{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "50"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "num_experiments"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from myst_nb import glue\n",
    "\n",
    "from src.commons import NUM_EXPERIMENTS\n",
    "\n",
    "glue('num_experiments', NUM_EXPERIMENTS, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Statistical verification of results\n",
    "\n",
    "In order to assess significance and performance of obtained results two statistical approaches were used. The majority of metrics were compared using the Bayesian estimation (BEST) method {cite}`kruschke2013bayesian`, while the other straightforward metrics were just averaged.\n",
    "\n",
    "## Bayesian analysis\n",
    "The Bayesian approach towards comparing data from multiple groups was used instead of traditional methods of _null hypothesis significance testing_ (NHST). They are more intuitive than the calculation and interpretation of _p-value_ scores, provides complete information about credible parameter values and allow more coherent inferences from data {cite}`dienes2011bayesian`.\n",
    "\n",
    "The perils of frequentist NHST approach when comparing machine learning classifiers were depicted by Benavoli in {cite}`benavoli2017time`, which is particularly suited for this work. He points the following reasons against using the NHST methods:\n",
    "- it does not estimate probability of hypotheses,\n",
    "- point-wise null hypothesis are practically always false,\n",
    "- the p-value does not separate between the effect size and the sample size,\n",
    "- it ignores magnitude and uncertainty,\n",
    "- it yields no information about the null hypothesis,\n",
    "- there is no principled way to decide the $\\alpha$ level\n",
    "\n",
    "Additionally, in 2016 the _[American Statistical Association](https://www.amstat.org/)_ made a statement against p-values {cite}`wasserstein2016asa` which might be a motivation for other disciplines to pursue the Bayesian approach.\n",
    "\n",
    "````{margin}\n",
    "```{admonition} T-distribution\n",
    "The T distribution, like the normal distribution, is bell-shaped and symmetric, but it has heavier tails, which means it tends to produce values that fall far from its mean.\n",
    "\n",
    "Tail heaviness is determined by a parameter called _degrees of freedom_ $\\nu$ with smaller values giving heavier tails, and with higher values making the T distribution resemble a standard normal distribution with a mean of 0, and a standard deviation of 1.\n",
    "```\n",
    "````\n",
    "\n",
    "In this work we focus on establishing a descriptive mathematical model of the data $D$ using the Equation {eq}`bayesian_approach`.\n",
    "\n",
    "```{math}\n",
    ":label: bayesian_approach\n",
    "\\underbrace{p(\\mu, \\sigma, \\nu|D)}_{\\text{posterior}} = \\underbrace{p(D|\\mu, \\sigma, \\nu)}_{\\text{likelihood}} \\times \\underbrace{p(\\mu, \\sigma, \\nu)}_{\\text{prior}} \\big/ \\underbrace{p(D)}_{\\text{evidence}}\n",
    "```\n",
    "\n",
    "Each experiment is performed {glue:}`num_experiments` times, generating independent samples, which according to the Central Limit Theorem, should be enough to consider it approximating the normal distribution {cite}`islam2018sample`. To further provide a robust solution towards dealing with potential outliers, the _Student t-distribution_ is chosen. The prior distribution, described with three parameters - $\\mu$ (expected mean value), $\\sigma$ (standard deviation) and $\\nu$ (degrees of freedom) is presented using the Equation {eq}`bayesian_prior`.\n",
    "\n",
    "```{math}\n",
    ":label: bayesian_prior\n",
    "\\begin{align}\n",
    "    \\mu &\\sim \\mathrm{N}(\\mu_D, \\sigma^2_D) \\\\\n",
    "    \\sigma &\\sim \\mathrm{U}(\\frac{1}{100}, 1000) \\\\\n",
    "    \\nu &\\sim \\mathrm{Exp}(\\frac{1}{29})\n",
    "\\end{align}\n",
    "```\n",
    "The posterior distribution is approximated to arbitrarily high accuracy by generating a large representative sample from it using _Markov chain Monte Carlo_ (MCMC) methods. It's sample provides many thousands of combinations of parameter values $<\\mu, \\sigma, \\nu>$. Each such combination of values is representative of credible parameter values that simultaneously accommodate the observed data and the prior distribution. From the MCMC sample, one can infer credible parameter values like the mean or standard deviation.\n",
    "\n",
    "To perform Bayesian estimation this work uses the publicly accesible [PyMC3](https://docs.pymc.io/en/v3/) framework for probabilistic programming in Python language.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}