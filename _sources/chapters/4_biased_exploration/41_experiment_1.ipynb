{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import List, Dict\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML, Markdown, DisplayObject, Pretty, TextDisplayObject\n",
    "from lcs.agents.acs2 import Configuration, ACS2\n",
    "from lcs.metrics import population_metrics\n",
    "from lcs.strategies.action_selection import EpsilonGreedy, ActionDelay, KnowledgeArray\n",
    "from tabulate import tabulate\n",
    "from myst_nb import glue\n",
    "\n",
    "from src.bayes_estimation import bayes_estimate\n",
    "from src.decorators import repeat, get_from_cache_or_run\n",
    "from src.metrics import parse_experiments_results, corridor_transition_knowledge, grid_transition_knowledge\n",
    "from src.visualization import biased_exploration_colors, PLOT_DPI\n",
    "\n",
    "NUM_EXPERIMENTS = 50\n",
    "COLORS = biased_exploration_colors()\n",
    "\n",
    "plt.ioff()  # turn off interactive plotting\n",
    "\n",
    "cache_dir = f'{pathlib.Path().absolute()}/cache'\n",
    "plot_dir = f'{pathlib.Path().absolute()}/plots'\n",
    "\n",
    "\n",
    "def run_experiment(env_provider, explore_trials, exploit_trials, **conf):\n",
    "    env = env_provider()\n",
    "    env.reset()\n",
    "\n",
    "    cfg = Configuration(**conf)\n",
    "\n",
    "    explorer = ACS2(cfg)\n",
    "    metrics_explore = explorer.explore(env, explore_trials)\n",
    "\n",
    "    exploiter = ACS2(cfg, explorer.population)\n",
    "    metrics_exploit = explorer.exploit(env, exploit_trials)\n",
    "\n",
    "    # Parse results into DataFrame\n",
    "    metrics_df = parse_experiments_results(metrics_explore, metrics_exploit, cfg.metrics_trial_frequency)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "def extract(combined_list):\n",
    "    env1_dfs = [result[0] for result in combined_list]\n",
    "    env2_dfs = [result[1] for result in combined_list]\n",
    "    env3_dfs = [result[2] for result in combined_list]\n",
    "    return env1_dfs, env2_dfs, env3_dfs\n",
    "\n",
    "\n",
    "def average_experiment_runs(runs_dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    return pd.concat(runs_dfs).groupby(['trial', 'phase']).mean().reset_index(level='phase')\n",
    "\n",
    "\n",
    "def plot(epsilon_greedy_df, action_delay_df, knowledge_array_df, op_initial_df,\n",
    "         env_name,\n",
    "         num_explore_trials,\n",
    "         first_knowledge_trials,\n",
    "         first_population_trials,\n",
    "         population_ylim,\n",
    "         text_box_loc,\n",
    "         plot_filename=None):\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Layout\n",
    "    gs = fig.add_gridspec(2, 2, wspace=.25, hspace=.4)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "    # Global title\n",
    "    fig.suptitle(f'Performance of [{env_name}] environment', fontsize=24)\n",
    "\n",
    "    # Knowledge\n",
    "    epsilon_greedy_df['knowledge'][:first_knowledge_trials].plot(label='Epsilon Greedy', c=COLORS['eg'], ax=ax1)\n",
    "    action_delay_df['knowledge'][:first_knowledge_trials].plot(label='Action Delay', c=COLORS['ad'], ax=ax1)\n",
    "    knowledge_array_df['knowledge'][:first_knowledge_trials].plot(label='Knowledge Array', c=COLORS['ka'], ax=ax1)\n",
    "    op_initial_df['knowledge'][:first_knowledge_trials].plot(label='Optimistic Initial Quality', c=COLORS['oiq'],\n",
    "                                                             ax=ax1)\n",
    "\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.set_title('Knowledge')\n",
    "    ax1.set_xlabel('Trial')\n",
    "    ax1.set_ylabel('Knowledge')\n",
    "    ax1.axhline(y=100, color='black', linewidth=1, linestyle=\"--\")\n",
    "    ax1.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "    # Population\n",
    "    epsilon_greedy_df['population'][:first_population_trials].plot(label='Epsilon Greedy', c=COLORS['eg'], ax=ax2)\n",
    "    action_delay_df['population'][:first_population_trials].plot(label='Action Delay', c=COLORS['ad'], ax=ax2)\n",
    "    knowledge_array_df['population'][:first_population_trials].plot(label='Knowledge Array', c=COLORS['ka'], ax=ax2)\n",
    "    op_initial_df['population'][:first_population_trials].plot(label='Optimistic Initial Quality', c=COLORS['oiq'],\n",
    "                                                               ax=ax2)\n",
    "\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.set_xlabel('Trial')\n",
    "    ax2.set_ylabel('Classifiers')\n",
    "    ax2.set_title('Classifiers Population')\n",
    "    ax2.set_ylim(population_ylim)\n",
    "    ax2.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f'))\n",
    "    ax2.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f'))\n",
    "\n",
    "    # Steps in trial\n",
    "    window = 3  # window for moving average\n",
    "    epsilon_greedy_df['steps_in_trial'].rolling(window=window).mean().plot(label='Epsilon Greedy', c=COLORS['eg'],\n",
    "                                                                           ax=ax3)\n",
    "    action_delay_df['steps_in_trial'].rolling(window=window).mean().plot(label='Action Delay', c=COLORS['ad'], ax=ax3)\n",
    "    knowledge_array_df['steps_in_trial'].rolling(window=window).mean().plot(label='Knowledge Array', c=COLORS['ka'],\n",
    "                                                                            ax=ax3)\n",
    "    op_initial_df['steps_in_trial'].rolling(window=window).mean().plot(label='Optimistic Initial Quality',\n",
    "                                                                       c=COLORS['oiq'], ax=ax3)\n",
    "\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.set_xlabel('Trial')\n",
    "    ax3.set_ylabel('Steps')\n",
    "    ax3.set_title('Steps in trial')\n",
    "    ax3.axvline(x=num_explore_trials, color='black', linewidth=1, linestyle=\"--\")\n",
    "    ax3.text(**text_box_loc, s=f'Moving average of {window} samples', style='italic',\n",
    "             bbox={'facecolor': 'red', 'alpha': 0.2, 'pad': 10})\n",
    "\n",
    "    # Create legend\n",
    "    handles, labels = ax3.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=4)\n",
    "\n",
    "    if plot_filename:\n",
    "        fig.savefig(plot_filename, dpi=PLOT_DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiment 1 - Multi-steps problems performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corridor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import gym_corridor  # noqa: F401\n",
    "from src.observation_wrappers import CorridorObservationWrapper\n",
    "\n",
    "\n",
    "def corridor20_env_provider():\n",
    "    import gym_corridor  # noqa: F401\n",
    "    return CorridorObservationWrapper(gym.make(f'corridor-20-v0'))\n",
    "\n",
    "\n",
    "def corridor40_env_provider():\n",
    "    import gym_corridor  # noqa: F401\n",
    "    return CorridorObservationWrapper(gym.make(f'corridor-40-v0'))\n",
    "\n",
    "\n",
    "def corridor100_env_provider():\n",
    "    import gym_corridor  # noqa: F401\n",
    "    return CorridorObservationWrapper(gym.make(f'corridor-100-v0'))\n",
    "\n",
    "\n",
    "# Function for calculating relevant metrics\n",
    "def corridor_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {\n",
    "        'knowledge': corridor_transition_knowledge(pop, env)\n",
    "    }\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "corridor_base_params = {\n",
    "    \"classifier_length\": 1,\n",
    "    \"number_of_possible_actions\": 2,\n",
    "    \"epsilon\": 0.8,\n",
    "    \"beta\": 0.2,\n",
    "    \"gamma\": 0.95,\n",
    "    \"initial_q\": 0.5,\n",
    "    \"theta_exp\": 50,\n",
    "    \"theta_ga\": 50,\n",
    "    \"do_ga\": True,\n",
    "    \"mu\": 0.03,\n",
    "    \"u_max\": 1,\n",
    "    \"metrics_trial_frequency\": 1,\n",
    "    \"user_metrics_collector_fcn\": corridor_metrics\n",
    "}\n",
    "\n",
    "# Start experiments\n",
    "corridor_explore_trials, corridor_exploit_trials = 60, 20\n",
    "USE_RAY = True\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/corridor/epsilon_greedy.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def corridor_epsilon_greedy():\n",
    "    corridor20 = run_experiment(corridor20_env_provider,\n",
    "                                corridor_explore_trials,\n",
    "                                corridor_exploit_trials,\n",
    "                                **(corridor_base_params | {'action_selector': EpsilonGreedy}))\n",
    "\n",
    "    corridor40 = run_experiment(corridor40_env_provider,\n",
    "                                corridor_explore_trials,\n",
    "                                corridor_exploit_trials,\n",
    "                                **(corridor_base_params | {'action_selector': EpsilonGreedy}))\n",
    "\n",
    "    corridor100 = run_experiment(corridor100_env_provider,\n",
    "                                 corridor_explore_trials,\n",
    "                                 corridor_exploit_trials,\n",
    "                                 **(corridor_base_params | {'action_selector': EpsilonGreedy}))\n",
    "\n",
    "    return corridor20, corridor40, corridor100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/corridor/action_delay.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def corridor_action_delay():\n",
    "    corridor20 = run_experiment(corridor20_env_provider,\n",
    "                                corridor_explore_trials,\n",
    "                                corridor_exploit_trials,\n",
    "                                **(corridor_base_params | {'action_selector': ActionDelay,\n",
    "                                                           'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    corridor40 = run_experiment(corridor40_env_provider,\n",
    "                                corridor_explore_trials,\n",
    "                                corridor_exploit_trials,\n",
    "                                **(corridor_base_params | {'action_selector': ActionDelay,\n",
    "                                                           'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    corridor100 = run_experiment(corridor100_env_provider,\n",
    "                                 corridor_explore_trials,\n",
    "                                 corridor_exploit_trials,\n",
    "                                 **(corridor_base_params | {'action_selector': ActionDelay,\n",
    "                                                            'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    return corridor20, corridor40, corridor100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/corridor/knowledge_array.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def corridor_knowledge_array():\n",
    "    corridor20 = run_experiment(corridor20_env_provider,\n",
    "                                corridor_explore_trials,\n",
    "                                corridor_exploit_trials,\n",
    "                                **(corridor_base_params | {'action_selector': KnowledgeArray,\n",
    "                                                           'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    corridor40 = run_experiment(corridor40_env_provider,\n",
    "                                corridor_explore_trials,\n",
    "                                corridor_exploit_trials,\n",
    "                                **(corridor_base_params | {'action_selector': KnowledgeArray,\n",
    "                                                           'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    corridor100 = run_experiment(corridor100_env_provider,\n",
    "                                 corridor_explore_trials,\n",
    "                                 corridor_exploit_trials,\n",
    "                                 **(corridor_base_params | {'action_selector': KnowledgeArray,\n",
    "                                                            'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    return corridor20, corridor40, corridor100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/corridor/oiq.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def corridor_oiq():\n",
    "    corridor20 = run_experiment(corridor20_env_provider,\n",
    "                                corridor_explore_trials,\n",
    "                                corridor_exploit_trials,\n",
    "                                **(corridor_base_params | {'action_selector': EpsilonGreedy,\n",
    "                                                           'biased_exploration_prob': 0.8}))\n",
    "\n",
    "    corridor40 = run_experiment(corridor40_env_provider,\n",
    "                                corridor_explore_trials,\n",
    "                                corridor_exploit_trials,\n",
    "                                **(corridor_base_params | {'action_selector': EpsilonGreedy,\n",
    "                                                           'biased_exploration_prob': 0.8}))\n",
    "\n",
    "    corridor100 = run_experiment(corridor100_env_provider,\n",
    "                                 corridor_explore_trials,\n",
    "                                 corridor_exploit_trials,\n",
    "                                 **(corridor_base_params | {'action_selector': EpsilonGreedy,\n",
    "                                                            'biased_exploration_prob': 0.8}))\n",
    "\n",
    "    return corridor20, corridor40, corridor100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Function for calculating relevant metrics\n",
    "def grid_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {\n",
    "        'knowledge': grid_transition_knowledge(pop, env)\n",
    "    }\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def grid20_env_provider():\n",
    "    import gym_grid  # noqa: F401\n",
    "    return gym.make(f'grid-20-v0')\n",
    "\n",
    "\n",
    "def grid40_env_provider():\n",
    "    import gym_grid  # noqa: F401\n",
    "    return gym.make(f'grid-40-v0')\n",
    "\n",
    "\n",
    "def grid100_env_provider():\n",
    "    import gym_grid  # noqa: F401\n",
    "    return gym.make(f'grid-100-v0')\n",
    "\n",
    "\n",
    "grid_base_params = {\n",
    "    \"classifier_length\": 2,\n",
    "    \"number_of_possible_actions\": 4,\n",
    "    \"epsilon\": 0.8,\n",
    "    \"beta\": 0.2,\n",
    "    \"gamma\": 0.95,\n",
    "    \"initial_q\": 0.5,\n",
    "    \"theta_exp\": 50,\n",
    "    \"theta_ga\": 50,\n",
    "    \"do_ga\": True,\n",
    "    \"mu\": 0.03,\n",
    "    \"u_max\": 1,\n",
    "    \"metrics_trial_frequency\": 1,\n",
    "    \"user_metrics_collector_fcn\": grid_metrics\n",
    "}\n",
    "\n",
    "# Start experiments\n",
    "grid_explore_trials, grid_exploit_trials = 60, 20\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/grid/epsilon_greedy.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def grid_epsilon_greedy():\n",
    "    grid20 = run_experiment(grid20_env_provider,\n",
    "                            grid_explore_trials,\n",
    "                            grid_exploit_trials,\n",
    "                            **(grid_base_params | {'action_selector': EpsilonGreedy}))\n",
    "\n",
    "    grid40 = run_experiment(grid40_env_provider,\n",
    "                            grid_explore_trials,\n",
    "                            grid_exploit_trials,\n",
    "                            **(grid_base_params | {'action_selector': EpsilonGreedy}))\n",
    "\n",
    "    grid100 = run_experiment(grid100_env_provider,\n",
    "                             grid_explore_trials,\n",
    "                             grid_exploit_trials,\n",
    "                             **(grid_base_params | {'action_selector': EpsilonGreedy}))\n",
    "\n",
    "    return grid20, grid40, grid100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/grid/action_delay.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def grid_action_delay():\n",
    "    grid20 = run_experiment(grid20_env_provider,\n",
    "                            grid_explore_trials,\n",
    "                            grid_exploit_trials,\n",
    "                            **(grid_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    grid40 = run_experiment(grid40_env_provider,\n",
    "                            grid_explore_trials,\n",
    "                            grid_exploit_trials,\n",
    "                            **(grid_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    grid100 = run_experiment(grid100_env_provider,\n",
    "                             grid_explore_trials,\n",
    "                             grid_exploit_trials,\n",
    "                             **(grid_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    return grid20, grid40, grid100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/grid/knowledge_array.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def grid_knowledge_array():\n",
    "    grid20 = run_experiment(grid20_env_provider,\n",
    "                            grid_explore_trials,\n",
    "                            grid_exploit_trials,\n",
    "                            **(grid_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    grid40 = run_experiment(grid40_env_provider,\n",
    "                            grid_explore_trials,\n",
    "                            grid_exploit_trials,\n",
    "                            **(grid_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    grid100 = run_experiment(grid100_env_provider,\n",
    "                             grid_explore_trials,\n",
    "                             grid_exploit_trials,\n",
    "                             **(grid_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    return grid20, grid40, grid100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/grid/oiq.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def grid_oiq():\n",
    "    grid_20 = run_experiment(grid20_env_provider,\n",
    "                             grid_explore_trials,\n",
    "                             grid_exploit_trials,\n",
    "                             **(grid_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "\n",
    "    grid_40 = run_experiment(grid40_env_provider,\n",
    "                             grid_explore_trials,\n",
    "                             grid_exploit_trials,\n",
    "                             **(grid_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "\n",
    "    grid_100 = run_experiment(grid100_env_provider,\n",
    "                              grid_explore_trials,\n",
    "                              grid_exploit_trials,\n",
    "                              **(grid_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "\n",
    "    return grid_20, grid_40, grid_100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Execute calculations\n",
    "corridor20_eg_dfs, corridor40_eg_dfs, corridor100_eg_dfs = extract(corridor_epsilon_greedy())\n",
    "corridor20_ad_dfs, corridor40_ad_dfs, corridor100_ad_dfs = extract(corridor_action_delay())\n",
    "corridor20_ka_dfs, corridor40_ka_dfs, corridor100_ka_dfs = extract(corridor_knowledge_array())\n",
    "corridor20_oiq_dfs, corridor40_oiq_dfs, corridor100_oiq_dfs = extract(corridor_oiq())\n",
    "\n",
    "# Plot results\n",
    "plot(\n",
    "    average_experiment_runs(corridor20_eg_dfs),\n",
    "    average_experiment_runs(corridor20_ad_dfs),\n",
    "    average_experiment_runs(corridor20_ka_dfs),\n",
    "    average_experiment_runs(corridor20_oiq_dfs),\n",
    "    env_name='Corridor-20',\n",
    "    num_explore_trials=corridor_explore_trials,\n",
    "    first_knowledge_trials=30,\n",
    "    first_population_trials=20,\n",
    "    population_ylim=(17, 40),\n",
    "    text_box_loc={\"x\": 63, \"y\": 120},\n",
    "    plot_filename=f'{plot_dir}/corridor-performance.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ":::{figure-md} corridor-fig\n",
    ":class: full-width\n",
    "<img src=\"plots/corridor-performance.png\">\n",
    "\n",
    "Performance in Corridor environment\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Execute calculations\n",
    "grid20_eg_dfs, grid40_eg_dfs, grid100_eg_dfs = extract(grid_epsilon_greedy())\n",
    "grid20_ad_dfs, grid40_ad_dfs, grid100_ad_dfs = extract(grid_action_delay())\n",
    "grid20_ka_dfs, grid40_ka_dfs, grid100_ka_dfs = extract(grid_knowledge_array())\n",
    "grid20_oiq_dfs, grid40_oiq_dfs, grid100_oiq_dfs = extract(grid_oiq())\n",
    "\n",
    "# Plot results\n",
    "plot(\n",
    "    average_experiment_runs(grid20_eg_dfs),\n",
    "    average_experiment_runs(grid20_ad_dfs),\n",
    "    average_experiment_runs(grid20_ka_dfs),\n",
    "    average_experiment_runs(grid20_oiq_dfs),\n",
    "    env_name='Grid-20',\n",
    "    num_explore_trials=grid_explore_trials,\n",
    "    first_knowledge_trials=10,\n",
    "    first_population_trials=30,\n",
    "    population_ylim=(70, 105),\n",
    "    text_box_loc={\"x\": 63, \"y\": 1000},\n",
    "    plot_filename=f'{plot_dir}/grid-performance.png'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ":::{figure-md} grid-fig\n",
    ":class: full-width\n",
    "<img src=\"plots/grid-performance.png\">\n",
    "\n",
    "Performance in Grid environment\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Statistical verification\n",
    "\n",
    "```{admonition} Hypothesis testing\n",
    ":class: tip\n",
    "In almost every plots the lines clearly converge (knowledge, population, steps in trial). Maybe what would be beneficial would be to futher investigate larger environment problems (sizes 20/40/100) with fixed number of trials and show the differences (probably in the table like exploration method vs environment).\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">      38.0 ± 0.0</td><td style=\"text-align: right;\">    38.0 ± 0.0</td><td style=\"text-align: right;\">       38.0 ± 0.0</td><td style=\"text-align: right;\">                  38.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">      38.0 ± 0.0</td><td style=\"text-align: right;\">    38.0 ± 0.0</td><td style=\"text-align: right;\">       38.0 ± 0.0</td><td style=\"text-align: right;\">                  38.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">     100.0 ± 0.0</td><td style=\"text-align: right;\">   100.0 ± 0.0</td><td style=\"text-align: right;\">      100.0 ± 0.0</td><td style=\"text-align: right;\">                 100.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">      0.02 ± 0.0</td><td style=\"text-align: right;\">    0.03 ± 0.0</td><td style=\"text-align: right;\">       0.05 ± 0.0</td><td style=\"text-align: right;\">                  0.02 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">          1000.0</td><td style=\"text-align: right;\">        1000.0</td><td style=\"text-align: right;\">           1000.0</td><td style=\"text-align: right;\">                      1000.0</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {
      "scrapbook": {
       "name": "corridor20",
       "mime_prefix": ""
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">      78.0 ± 0.0</td><td style=\"text-align: right;\">    78.0 ± 0.0</td><td style=\"text-align: right;\">       78.0 ± 0.0</td><td style=\"text-align: right;\">                  78.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">      78.0 ± 0.0</td><td style=\"text-align: right;\">    78.0 ± 0.0</td><td style=\"text-align: right;\">       78.0 ± 0.0</td><td style=\"text-align: right;\">                  78.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">     100.0 ± 0.0</td><td style=\"text-align: right;\">   100.0 ± 0.0</td><td style=\"text-align: right;\">      100.0 ± 0.0</td><td style=\"text-align: right;\">                 100.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">      0.06 ± 0.0</td><td style=\"text-align: right;\">    0.07 ± 0.0</td><td style=\"text-align: right;\">       0.09 ± 0.0</td><td style=\"text-align: right;\">                  0.06 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">           949.0</td><td style=\"text-align: right;\">         998.0</td><td style=\"text-align: right;\">           1000.0</td><td style=\"text-align: right;\">                       962.0</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {
      "scrapbook": {
       "name": "corridor40",
       "mime_prefix": ""
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">     198.0 ± 0.0</td><td style=\"text-align: right;\">   198.0 ± 0.0</td><td style=\"text-align: right;\">      198.0 ± 0.0</td><td style=\"text-align: right;\">                 198.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">   195.25 ± 0.53</td><td style=\"text-align: right;\"> 195.78 ± 0.38</td><td style=\"text-align: right;\">      196.0 ± 0.0</td><td style=\"text-align: right;\">               195.67 ± 0.39</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">    98.63 ± 0.27</td><td style=\"text-align: right;\">   98.88 ± 0.2</td><td style=\"text-align: right;\">      98.98 ± 0.0</td><td style=\"text-align: right;\">                98.83 ± 0.21</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">      0.15 ± 0.0</td><td style=\"text-align: right;\">    0.16 ± 0.0</td><td style=\"text-align: right;\">       0.17 ± 0.0</td><td style=\"text-align: right;\">                  0.16 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">           228.0</td><td style=\"text-align: right;\">         222.0</td><td style=\"text-align: right;\">            329.0</td><td style=\"text-align: right;\">                       217.0</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {
      "scrapbook": {
       "name": "corridor100",
       "mime_prefix": ""
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_models(dfs: Dict[str, pd.DataFrame], field: str, query_condition: str):\n",
    "    results = {}\n",
    "\n",
    "    for name, df in dfs.items():\n",
    "        data_arr = df.query(query_condition)[field].to_numpy()\n",
    "        bayes_model = bayes_estimate(data_arr)\n",
    "        results[name] = (bayes_model['mu'], bayes_model['std'])\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_average_reward(dfs: Dict[str, pd.DataFrame]):\n",
    "    results = {}\n",
    "\n",
    "    for name, df in dfs.items():\n",
    "        results[name] = df.query('phase == \"exploit\"')['reward'].mean()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "experiments_data = {\n",
    "    'corridor20_eg': pd.concat(corridor20_eg_dfs),\n",
    "    'corridor40_eg': pd.concat(corridor40_eg_dfs),\n",
    "    'corridor100_eg': pd.concat(corridor100_eg_dfs),\n",
    "\n",
    "    'corridor20_ad': pd.concat(corridor20_ad_dfs),\n",
    "    'corridor40_ad': pd.concat(corridor40_ad_dfs),\n",
    "    'corridor100_ad': pd.concat(corridor100_ad_dfs),\n",
    "\n",
    "    'corridor20_ka': pd.concat(corridor20_ka_dfs),\n",
    "    'corridor40_ka': pd.concat(corridor40_ka_dfs),\n",
    "    'corridor100_ka': pd.concat(corridor100_ka_dfs),\n",
    "\n",
    "    'corridor20_oiq': pd.concat(corridor20_oiq_dfs),\n",
    "    'corridor40_oiq': pd.concat(corridor40_oiq_dfs),\n",
    "    'corridor100_oiq': pd.concat(corridor100_oiq_dfs),\n",
    "\n",
    "    'grid20_eg': pd.concat(grid20_eg_dfs),\n",
    "    'grid40_eg': pd.concat(grid40_eg_dfs),\n",
    "    'grid100_eg': pd.concat(grid100_eg_dfs),\n",
    "\n",
    "    'grid20_ad': pd.concat(grid20_ad_dfs),\n",
    "    'grid40_ad': pd.concat(grid40_ad_dfs),\n",
    "    'grid100_ad': pd.concat(grid100_ad_dfs),\n",
    "\n",
    "    'grid20_ka': pd.concat(grid20_ka_dfs),\n",
    "    'grid40_ka': pd.concat(grid40_ka_dfs),\n",
    "    'grid100_ka': pd.concat(grid100_ka_dfs),\n",
    "\n",
    "    'grid20_oiq': pd.concat(grid20_oiq_dfs),\n",
    "    'grid40_oiq': pd.concat(grid40_oiq_dfs),\n",
    "    'grid100_oiq': pd.concat(grid100_oiq_dfs)\n",
    "}\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/bayes/population.dill')\n",
    "def build_population_models(dfs: Dict[str, pd.DataFrame]):\n",
    "    return build_models(dfs, field='population', query_condition=f'trial == {corridor_explore_trials - 1}')\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/bayes/reliable.dill')\n",
    "def build_reliable_models(dfs: Dict[str, pd.DataFrame]):\n",
    "    return build_models(dfs, field='reliable', query_condition=f'trial == {corridor_explore_trials - 1}')\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/bayes/knowledge.dill')\n",
    "def build_knowledge_models(dfs: Dict[str, pd.DataFrame]):\n",
    "    return build_models(dfs, field='knowledge', query_condition=f'trial == {corridor_explore_trials - 1}')\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/bayes/perf_time.dill')\n",
    "def build_perf_time_models(dfs: Dict[str, pd.DataFrame]):\n",
    "    return build_models(dfs, field='perf_time', query_condition=f'phase == \"explore\"')\n",
    "\n",
    "\n",
    "population_models = build_population_models(experiments_data)\n",
    "reliable_models = build_reliable_models(experiments_data)\n",
    "knowledge_models = build_knowledge_models(experiments_data)\n",
    "perf_time_models = build_perf_time_models(experiments_data)\n",
    "avg_rewards = get_average_reward(experiments_data)\n",
    "\n",
    "\n",
    "def print_bayes_table(name_prefix, population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards):\n",
    "    print_row = lambda r: f'{round(r[0].mean(), 2)} ± {round(r[0].std(), 2)}'\n",
    "\n",
    "    key_names = [name for name in experiments_data.keys() if name.startswith(name_prefix)]\n",
    "\n",
    "    bayes_table_data = [\n",
    "        ['population of classifiers'] + [print_row(v) for name, v in population_models.items() if name in key_names],\n",
    "        ['reliable classifiers'] + [print_row(v) for name, v in reliable_models.items() if name in key_names],\n",
    "        ['knowledge'] + [print_row(v) for name, v in knowledge_models.items() if name in key_names],\n",
    "        ['trial execution time'] + [print_row(v) for name, v in perf_time_models.items() if name in key_names],\n",
    "        ['average exploit reward'] + [f'{round(v, 2)}' for name, v in avg_rewards.items() if name in key_names],\n",
    "    ]\n",
    "\n",
    "    table = tabulate(bayes_table_data,\n",
    "                     headers=['', 'Epsilon Greedy', 'Action Delay', 'Knowledge Array', 'Optimistic Initial Quality'],\n",
    "                     tablefmt=\"html\",\n",
    "                     stralign='right')\n",
    "    return HTML(table)\n",
    "\n",
    "# Add glue for rendering output in tabs\n",
    "glue(\"corridor20\", print_bayes_table('corridor20', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards))\n",
    "glue(\"corridor40\", print_bayes_table('corridor40', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards))\n",
    "glue(\"corridor100\", print_bayes_table('corridor100', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards))\n",
    "glue(\"grid20\", print_bayes_table('grid20', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards))\n",
    "glue(\"grid40\", print_bayes_table('grid40', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards))\n",
    "glue(\"grid100\", print_bayes_table('grid100', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Corridor\n",
    "```{tabbed} Corridor 20\n",
    "{glue:}`corridor20`\n",
    "```\n",
    "\n",
    "```{tabbed} Corridor 40\n",
    "{glue:}`corridor40`\n",
    "```\n",
    "\n",
    "```{tabbed} Corridor 100\n",
    "{glue:}`corridor100`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Grid\n",
    "```{tabbed} Grid 20\n",
    "{glue:}`grid20`\n",
    "```\n",
    "\n",
    "```{tabbed} Grid 40\n",
    "{glue:}`grid40`\n",
    "```\n",
    "\n",
    "```{tabbed} Grid 100\n",
    "{glue:}`grid100`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Observations\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Software packages used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<details>\n<summary>Click to view session information</summary>\n<pre>\n-----\ngym                 0.21.0\ngym_corridor        NA\nlcs                 NA\nmatplotlib          3.5.1\nmyst_nb             0.13.1\npandas              1.4.0\npydev_jupyter_utils NA\npydev_jupyter_vars  NA\nsession_info        1.0.0\nsrc                 (embedded book's utils module)\ntabulate            0.8.9\n-----\n</pre>\n<details>\n<summary>Click to view modules imported as dependencies</summary>\n<pre>\nPIL                 8.4.0\narviz               0.11.2\nasttokens           NA\nattr                21.4.0\nbabel               2.9.1\nbackcall            0.2.0\nbeta_ufunc          NA\nbinom_ufunc         NA\nbrotli              NA\ncachetools          5.0.0\ncertifi             2021.10.08\ncffi                1.15.0\ncftime              1.5.2\ncharset_normalizer  2.0.10\nclick               7.1.2\ncloudpickle         2.0.0\ncolorama            0.4.4\ncolorful            0.5.4\ncolorful_orig       0.5.4\ncryptography        36.0.1\ncycler              0.10.0\ncython_runtime      NA\ndatabricks_cli      NA\ndateutil            2.8.2\ndebugpy             1.5.1\ndecorator           5.1.1\ndefusedxml          0.7.1\ndill                0.3.4\ndocutils            0.16\nentrypoints         0.3\nexecuting           0.8.2\nfastprogress        0.2.7\nfilelock            3.4.2\ngoogle              NA\ngreenlet            1.1.2\ngrpc                1.43.0\nhiredis             2.0.0\nidna                3.3\nimagesize           NA\nimportlib_metadata  NA\nipykernel           6.7.0\nipython_genutils    0.2.0\nipywidgets          7.6.5\njedi                0.18.1\njinja2              3.0.3\njsonschema          3.2.0\njupyter_cache       0.4.3\njupyter_sphinx      0.3.2\njupyterlab_pygments 0.1.2\nkiwisolver          1.3.2\nlinkify_it          1.0.3\nmarkdown_it         1.1.0\nmarkupsafe          2.0.1\nmatplotlib_inline   NA\nmdit_py_plugins     0.2.8\nmistune             0.8.4\nmlflow              1.23.1\nmpl_toolkits        NA\nmsgpack             1.0.3\nmyst_parser         0.15.2\nnbclient            0.5.10\nnbconvert           6.4.1\nnbformat            5.1.3\nnbinom_ufunc        NA\nnetCDF4             1.5.8\nnumpy               1.22.1\npackaging           21.3\npandocfilters       NA\nparso               0.8.3\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nprompt_toolkit      3.0.26\npsutil              5.9.0\nptyprocess          0.7.0\npure_eval           0.2.2\npvectorc            NA\npydevconsole        NA\npydevd_file_utils   NA\npydevd_plugins      NA\npygments            2.11.2\npylab               NA\npymc3               3.11.4\npyparsing           3.0.7\npyrsistent          NA\npytz                2021.3\nray                 1.9.2\nredis               4.1.2\nrequests            2.27.1\nscipy               1.7.3\nsemver              2.13.0\nsetproctitle        1.2.2\nsetuptools          60.5.0\nsix                 1.16.0\nsocks               1.7.1\nsphinx              4.4.0\nsphinxcontrib       NA\nsqlalchemy          1.4.31\nstack_data          0.1.4\ntestpath            0.5.0\ntheano              1.1.2\ntornado             6.1\ntqdm                4.62.3\ntraitlets           5.1.1\ntyping_extensions   NA\nuc_micro            1.0.1\nunicodedata2        NA\nurllib3             1.26.8\nwcwidth             0.2.5\nxarray              0.21.0\nyaml                6.0\nzipp                NA\nzmq                 22.3.0\n</pre>\n</details> <!-- seems like this ends pre, so might as well be explicit -->\n<pre>\n-----\nIPython             8.0.1\njupyter_client      7.1.2\njupyter_core        4.9.1\nnotebook            6.4.8\n-----\nPython 3.9.10 | packaged by conda-forge | (main, Jan 28 2022, 19:23:19) [GCC 9.4.0]\nLinux-5.13.0-27-generic-x86_64-with-glibc2.31\n-----\nSession information updated at 2022-01-29 14:45\n</pre>\n</details>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}