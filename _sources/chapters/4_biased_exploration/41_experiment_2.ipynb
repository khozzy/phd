{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import List, Dict\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from lcs.agents.acs2 import Configuration, ACS2\n",
    "from lcs.metrics import population_metrics\n",
    "from lcs.strategies.action_selection import EpsilonGreedy, ActionDelay, KnowledgeArray\n",
    "from myst_nb import glue\n",
    "from tabulate import tabulate\n",
    "\n",
    "from src.bayes_estimation import bayes_estimate\n",
    "from src.commons import NUM_EXPERIMENTS\n",
    "from src.decorators import repeat, get_from_cache_or_run\n",
    "from src.metrics import parse_experiments_results, corridor_transition_knowledge, grid_transition_knowledge\n",
    "from src.utils import build_plots_dir_path, build_cache_dir_path\n",
    "from src.visualization import biased_exploration_colors, PLOT_DPI\n",
    "\n",
    "COLORS = biased_exploration_colors()\n",
    "\n",
    "plt.ioff()  # turn off interactive plotting\n",
    "\n",
    "root_dir = pathlib.Path().cwd().parent.parent.parent\n",
    "cwd_dir = pathlib.Path().cwd()\n",
    "\n",
    "plot_dir = build_plots_dir_path(root_dir) /  cwd_dir.name\n",
    "cache_dir = build_cache_dir_path(root_dir) /  cwd_dir.name\n",
    "\n",
    "\n",
    "def run_experiment(env_provider, explore_trials, exploit_trials, **conf):\n",
    "    env = env_provider()\n",
    "    env.reset()\n",
    "\n",
    "    cfg = Configuration(**conf)\n",
    "\n",
    "    explorer = ACS2(cfg)\n",
    "    metrics_explore = explorer.explore(env, explore_trials)\n",
    "\n",
    "    exploiter = ACS2(cfg, explorer.population)\n",
    "    metrics_exploit = explorer.exploit(env, exploit_trials)\n",
    "\n",
    "    # Parse results into DataFrame\n",
    "    metrics_df = parse_experiments_results(metrics_explore, metrics_exploit, cfg.metrics_trial_frequency)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "def extract(combined_list):\n",
    "    env1_dfs = [result[0] for result in combined_list]\n",
    "    env2_dfs = [result[1] for result in combined_list]\n",
    "    env3_dfs = [result[2] for result in combined_list]\n",
    "    return env1_dfs, env2_dfs, env3_dfs\n",
    "\n",
    "\n",
    "def average_experiment_runs(runs_dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    return pd.concat(runs_dfs).groupby(['trial', 'phase']).mean().reset_index(level='phase')\n",
    "\n",
    "\n",
    "def plot(epsilon_greedy_df, action_delay_df, knowledge_array_df, op_initial_df,\n",
    "         env_name,\n",
    "         num_explore_trials,\n",
    "         first_knowledge_trials,\n",
    "         first_population_trials,\n",
    "         population_ylim,\n",
    "         text_box_loc,\n",
    "         plot_filename=None):\n",
    "    fig = plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Layout\n",
    "    gs = fig.add_gridspec(2, 2, wspace=.25, hspace=.4)\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax3 = fig.add_subplot(gs[1, :])\n",
    "\n",
    "    # Global title\n",
    "    fig.suptitle(f'Performance of [{env_name}] environment', fontsize=24)\n",
    "\n",
    "    # Knowledge\n",
    "    epsilon_greedy_df['knowledge'][:first_knowledge_trials].plot(label='Epsilon Greedy', c=COLORS['eg'], ax=ax1)\n",
    "    action_delay_df['knowledge'][:first_knowledge_trials].plot(label='Action Delay', c=COLORS['ad'], ax=ax1)\n",
    "    knowledge_array_df['knowledge'][:first_knowledge_trials].plot(label='Knowledge Array', c=COLORS['ka'], ax=ax1)\n",
    "    op_initial_df['knowledge'][:first_knowledge_trials].plot(label='Optimistic Initial Quality', c=COLORS['oiq'], ax=ax1)\n",
    "\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "    ax1.set_title('Knowledge')\n",
    "    ax1.set_xlabel('Trial')\n",
    "    ax1.set_ylabel('Knowledge')\n",
    "    ax1.axhline(y=100, color='black', linewidth=1, linestyle=\"--\")\n",
    "    ax1.yaxis.set_major_formatter(mtick.PercentFormatter())\n",
    "\n",
    "    # Population\n",
    "    epsilon_greedy_df['population'][:first_population_trials].plot(label='Epsilon Greedy', c=COLORS['eg'], ax=ax2)\n",
    "    action_delay_df['population'][:first_population_trials].plot(label='Action Delay', c=COLORS['ad'], ax=ax2)\n",
    "    knowledge_array_df['population'][:first_population_trials].plot(label='Knowledge Array', c=COLORS['ka'], ax=ax2)\n",
    "    op_initial_df['population'][:first_population_trials].plot(label='Optimistic Initial Quality', c=COLORS['oiq'], ax=ax2)\n",
    "\n",
    "    ax2.spines['top'].set_visible(False)\n",
    "    ax2.spines['right'].set_visible(False)\n",
    "    ax2.set_xlabel('Trial')\n",
    "    ax2.set_ylabel('Classifiers')\n",
    "    ax2.set_title('Classifiers Population')\n",
    "    ax2.set_ylim(population_ylim)\n",
    "    ax2.xaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f'))\n",
    "    ax2.yaxis.set_major_formatter(mtick.FormatStrFormatter('%.0f'))\n",
    "\n",
    "    # Steps in trial\n",
    "    window = 3  # window for moving average\n",
    "    epsilon_greedy_df['steps_in_trial'].rolling(window=window).mean().plot(label='Epsilon Greedy', c=COLORS['eg'], ax=ax3)\n",
    "    action_delay_df['steps_in_trial'].rolling(window=window).mean().plot(label='Action Delay', c=COLORS['ad'], ax=ax3)\n",
    "    knowledge_array_df['steps_in_trial'].rolling(window=window).mean().plot(label='Knowledge Array', c=COLORS['ka'], ax=ax3)\n",
    "    op_initial_df['steps_in_trial'].rolling(window=window).mean().plot(label='Optimistic Initial Quality', c=COLORS['oiq'], ax=ax3)\n",
    "\n",
    "    ax3.spines['top'].set_visible(False)\n",
    "    ax3.spines['right'].set_visible(False)\n",
    "    ax3.set_xlabel('Trial')\n",
    "    ax3.set_ylabel('Steps')\n",
    "    ax3.set_title('Steps in trial')\n",
    "    ax3.axvline(x=num_explore_trials, color='black', linewidth=1, linestyle=\"--\")\n",
    "    ax3.text(**text_box_loc, s=f'Moving average of {window} samples', style='italic',\n",
    "             bbox={'facecolor': 'red', 'alpha': 0.2, 'pad': 10})\n",
    "\n",
    "    # Create legend\n",
    "    handles, labels = ax3.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=4)\n",
    "\n",
    "    if plot_filename:\n",
    "        fig.savefig(plot_filename, dpi=PLOT_DPI)\n",
    "\n",
    "    return fig\n",
    "\n",
    "USE_RAY = True\n",
    "explore_trials, exploit_trials = 60, 20\n",
    "\n",
    "glue('41_e2_explore_trials', explore_trials, display=False)\n",
    "glue('41_e2_exploit_trials', exploit_trials, display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiment 2 - Multi-steps problems performance\n",
    "Both [](section-topics-environments-corridor) and [](section-topics-environments-grid) multiple-step environments were used for verifying the biased exploration strategies. In each case the ACS2 agent starts by performing {glue:}`41_e2_explore_trials` explore trials with selected strategy, followed by {glue:}`41_e2_exploit_trials` where the evolved population is validated.\n",
    "\n",
    "The following metrics are considered:\n",
    "- knowledge - depicting the process of building an internal model,\n",
    "- population size - demonstrate the total number of classifiers,\n",
    "- steps in a trial - both in explore and exploit phase.\n",
    "\n",
    "Figures {numref}`{number} <41-e2-corridor-fig>` and {numref}`{number} <41-e2-grid-fig>` presents the metric evolution for the basic versions of Corridor and Grid problems, containing 20 and 400 distinct states respectively, but the overall metrics look similar for larger instances. Additionally, for the Corridor, the cross-over capability of the agent was switched off because of the unit length of the perception vector $\\sigma$.\n",
    "\n",
    "To amplify the agent's motivation for exploring possible options, each problem was additionally increased to the sizes of $n=40$ and $n=100$. Last trial statistical inferences were collected in all cases to estimate overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    " **Corridor ACS2 parameters**\n",
    "\n",
    "$\\beta=0.2$, $\\gamma = 0.95$, $\\theta_r = 0.9$, $\\theta_i=0.1$, $\\epsilon = 0.8$ $\\theta_{GA} = 50$, $\\theta_{AS}=20$, $\\theta_{exp}=50$, $m_u=0.03$, $\\chi=0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import gym_corridor  # noqa: F401\n",
    "from src.observation_wrappers import CorridorObservationWrapper\n",
    "\n",
    "\n",
    "def corridor20_env_provider():\n",
    "    import gym_corridor  # noqa: F401\n",
    "    return CorridorObservationWrapper(gym.make(f'corridor-20-v0'))\n",
    "\n",
    "\n",
    "def corridor40_env_provider():\n",
    "    import gym_corridor  # noqa: F401\n",
    "    return CorridorObservationWrapper(gym.make(f'corridor-40-v0'))\n",
    "\n",
    "\n",
    "def corridor100_env_provider():\n",
    "    import gym_corridor  # noqa: F401\n",
    "    return CorridorObservationWrapper(gym.make(f'corridor-100-v0'))\n",
    "\n",
    "\n",
    "# Function for calculating relevant metrics\n",
    "def corridor_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {\n",
    "        'knowledge': corridor_transition_knowledge(pop, env)\n",
    "    }\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "corridor_base_params = {\n",
    "    \"classifier_length\": 1,\n",
    "    \"number_of_possible_actions\": 2,\n",
    "    \"epsilon\": 0.8,\n",
    "    \"beta\": 0.2,\n",
    "    \"gamma\": 0.95,\n",
    "    \"initial_q\": 0.5,\n",
    "    \"theta_exp\": 50,\n",
    "    \"theta_ga\": 50,\n",
    "    \"do_ga\": True,\n",
    "    \"mu\": 0.03,\n",
    "    \"u_max\": 1,\n",
    "    \"metrics_trial_frequency\": 1,\n",
    "    \"user_metrics_collector_fcn\": corridor_metrics\n",
    "}\n",
    "\n",
    "# Start experiments\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/corridor/epsilon_greedy.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def corridor_epsilon_greedy():\n",
    "    corridor20 = run_experiment(corridor20_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': EpsilonGreedy}))\n",
    "    corridor40 = run_experiment(corridor40_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': EpsilonGreedy}))\n",
    "    corridor100 = run_experiment(corridor100_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': EpsilonGreedy}))\n",
    "    return corridor20, corridor40, corridor100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/corridor/action_delay.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def corridor_action_delay():\n",
    "    corridor20 = run_experiment(corridor20_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "    corridor40 = run_experiment(corridor40_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "    corridor100 = run_experiment(corridor100_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "    return corridor20, corridor40, corridor100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/corridor/knowledge_array.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def corridor_knowledge_array():\n",
    "    corridor20 = run_experiment(corridor20_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "    corridor40 = run_experiment(corridor40_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "    corridor100 = run_experiment(corridor100_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "    return corridor20, corridor40, corridor100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/corridor/oiq.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def corridor_oiq():\n",
    "    corridor20 = run_experiment(corridor20_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "    corridor40 = run_experiment(corridor40_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "    corridor100 = run_experiment(corridor100_env_provider, explore_trials, exploit_trials, **(corridor_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "    return corridor20, corridor40, corridor100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Grid ACS2 parameters**\n",
    "\n",
    "$\\beta=0.2$, $\\gamma = 0.95$, $\\theta_r = 0.9$, $\\theta_i=0.1$, $\\epsilon = 0.8$ $\\theta_{GA} = 50$, $\\theta_{AS}=20$, $\\theta_{exp}=50$, $m_u=0.03$, $u_{max}=1$, $\\chi=0.8$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# Function for calculating relevant metrics\n",
    "def grid_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {\n",
    "        'knowledge': grid_transition_knowledge(pop, env)\n",
    "    }\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def grid20_env_provider():\n",
    "    import gym_grid  # noqa: F401\n",
    "    return gym.make(f'grid-20-v0')\n",
    "\n",
    "\n",
    "def grid40_env_provider():\n",
    "    import gym_grid  # noqa: F401\n",
    "    return gym.make(f'grid-40-v0')\n",
    "\n",
    "\n",
    "def grid100_env_provider():\n",
    "    import gym_grid  # noqa: F401\n",
    "    return gym.make(f'grid-100-v0')\n",
    "\n",
    "\n",
    "grid_base_params = {\n",
    "    \"classifier_length\": 2,\n",
    "    \"number_of_possible_actions\": 4,\n",
    "    \"epsilon\": 0.8,\n",
    "    \"beta\": 0.2,\n",
    "    \"gamma\": 0.95,\n",
    "    \"initial_q\": 0.5,\n",
    "    \"theta_exp\": 50,\n",
    "    \"theta_ga\": 50,\n",
    "    \"do_ga\": True,\n",
    "    \"mu\": 0.03,\n",
    "    \"u_max\": 1,\n",
    "    \"metrics_trial_frequency\": 1,\n",
    "    \"user_metrics_collector_fcn\": grid_metrics\n",
    "}\n",
    "\n",
    "# Start experiments\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/grid/epsilon_greedy.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def grid_epsilon_greedy():\n",
    "    grid20 = run_experiment(grid20_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': EpsilonGreedy}))\n",
    "    grid40 = run_experiment(grid40_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': EpsilonGreedy}))\n",
    "    grid100 = run_experiment(grid100_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': EpsilonGreedy}))\n",
    "    return grid20, grid40, grid100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/grid/action_delay.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def grid_action_delay():\n",
    "    grid20 = run_experiment(grid20_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "    grid40 = run_experiment(grid40_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "    grid100 = run_experiment(grid100_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "    return grid20, grid40, grid100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/grid/knowledge_array.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def grid_knowledge_array():\n",
    "    grid20 = run_experiment(grid20_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "    grid40 = run_experiment(grid40_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "    grid100 = run_experiment(grid100_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "    return grid20, grid40, grid100\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/grid/oiq.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def grid_oiq():\n",
    "    grid_20 = run_experiment(grid20_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "    grid_40 = run_experiment(grid40_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "    grid_100 = run_experiment(grid100_env_provider, explore_trials, exploit_trials, **(grid_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "    return grid_20, grid_40, grid_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [1]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Execute calculations\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m corridor20_eg_dfs, corridor40_eg_dfs, corridor100_eg_dfs \u001B[38;5;241m=\u001B[39m \u001B[43mextract\u001B[49m(corridor_epsilon_greedy())\n\u001B[1;32m      3\u001B[0m corridor20_ad_dfs, corridor40_ad_dfs, corridor100_ad_dfs \u001B[38;5;241m=\u001B[39m extract(corridor_action_delay())\n\u001B[1;32m      4\u001B[0m corridor20_ka_dfs, corridor40_ka_dfs, corridor100_ka_dfs \u001B[38;5;241m=\u001B[39m extract(corridor_knowledge_array())\n",
      "\u001B[0;31mNameError\u001B[0m: name 'extract' is not defined"
     ]
    }
   ],
   "source": [
    "# Execute calculations\n",
    "corridor20_eg_dfs, corridor40_eg_dfs, corridor100_eg_dfs = extract(corridor_epsilon_greedy())\n",
    "corridor20_ad_dfs, corridor40_ad_dfs, corridor100_ad_dfs = extract(corridor_action_delay())\n",
    "corridor20_ka_dfs, corridor40_ka_dfs, corridor100_ka_dfs = extract(corridor_knowledge_array())\n",
    "corridor20_oiq_dfs, corridor40_oiq_dfs, corridor100_oiq_dfs = extract(corridor_oiq())\n",
    "\n",
    "grid20_eg_dfs, grid40_eg_dfs, grid100_eg_dfs = extract(grid_epsilon_greedy())\n",
    "grid20_ad_dfs, grid40_ad_dfs, grid100_ad_dfs = extract(grid_action_delay())\n",
    "grid20_ka_dfs, grid40_ka_dfs, grid100_ka_dfs = extract(grid_knowledge_array())\n",
    "grid20_oiq_dfs, grid40_oiq_dfs, grid100_oiq_dfs = extract(grid_oiq())\n",
    "\n",
    "# Plot results\n",
    "glue('41-e2-corridor-fig', plot(\n",
    "    average_experiment_runs(corridor20_eg_dfs),\n",
    "    average_experiment_runs(corridor20_ad_dfs),\n",
    "    average_experiment_runs(corridor20_ka_dfs),\n",
    "    average_experiment_runs(corridor20_oiq_dfs),\n",
    "    env_name='Corridor-20',\n",
    "    num_explore_trials=explore_trials,\n",
    "    first_knowledge_trials=30,\n",
    "    first_population_trials=20,\n",
    "    population_ylim=(17, 40),\n",
    "    text_box_loc={\"x\": 63, \"y\": 120},\n",
    "    plot_filename=f'{plot_dir}/corridor-performance.png'\n",
    "), display=False)\n",
    "\n",
    "glue('41-e2-grid-fig', plot(\n",
    "    average_experiment_runs(grid20_eg_dfs),\n",
    "    average_experiment_runs(grid20_ad_dfs),\n",
    "    average_experiment_runs(grid20_ka_dfs),\n",
    "    average_experiment_runs(grid20_oiq_dfs),\n",
    "    env_name='Grid-20',\n",
    "    num_explore_trials=explore_trials,\n",
    "    first_knowledge_trials=10,\n",
    "    first_population_trials=30,\n",
    "    population_ylim=(70, 105),\n",
    "    text_box_loc={\"x\": 63, \"y\": 1000},\n",
    "    plot_filename=f'{plot_dir}/grid-performance.png'\n",
    "), display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "````{tabbed} Corridor\n",
    "```{glue:figure} 41-e2-corridor-fig\n",
    ":name: \"41-e2-corridor-fig\"\n",
    "Performance of Corridor-20 environment. {glue:}`41_e2_explore_trials` exploration and {glue:}`41_e2_exploit_trials` exploitation trials averaged over {glue:}`num_experiments` runs. _Steps in a trial_ was plotted with a moving average of 3 last steps for clarity. No explicit discretizer was needed. The maximum number of steps in a trial is 200. The dotted vertical line indicates the execution of explore and exploit phases.\n",
    "```\n",
    "````\n",
    "\n",
    "````{tabbed} Grid\n",
    "```{glue:figure} 41-e2-grid-fig\n",
    ":name: \"41-e2-grid-fig\"\n",
    "Performance of Grid-20 environment. {glue:}`41_e2_explore_trials` exploration and {glue:}`41_e2_exploit_trials` exploitation trials averaged over {glue:}`num_experiments` runs. _Steps in a trial_ was plotted with a moving average of 3 last steps for clarity. No explicit discretizer was needed. The maximum number of steps in a trial is 2000. The dotted vertical line indicates the execution of explore and exploit phases.\n",
    "```\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Statistical verification\n",
    "To statistically assess the population size, the posterior data distribution was generated using the BEST method with {glue:}`num_experiments` metric values collected in the last trial. For the obtained reward, the average value from exploit trials is considered a representative state of algorithm performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input",
     "remove-output"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">      38.0 ± 0.0</td><td style=\"text-align: right;\">    38.0 ± 0.0</td><td style=\"text-align: right;\">       38.0 ± 0.0</td><td style=\"text-align: right;\">                  38.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">      38.0 ± 0.0</td><td style=\"text-align: right;\">    38.0 ± 0.0</td><td style=\"text-align: right;\">       38.0 ± 0.0</td><td style=\"text-align: right;\">                  38.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">     100.0 ± 0.0</td><td style=\"text-align: right;\">   100.0 ± 0.0</td><td style=\"text-align: right;\">      100.0 ± 0.0</td><td style=\"text-align: right;\">                 100.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">      0.02 ± 0.0</td><td style=\"text-align: right;\">    0.03 ± 0.0</td><td style=\"text-align: right;\">       0.05 ± 0.0</td><td style=\"text-align: right;\">                  0.02 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">          1000.0</td><td style=\"text-align: right;\">        1000.0</td><td style=\"text-align: right;\">           1000.0</td><td style=\"text-align: right;\">                      1000.0</td></tr>\n</tbody>\n</table>",
      "application/papermill.record/text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "corridor20"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">      78.0 ± 0.0</td><td style=\"text-align: right;\">    78.0 ± 0.0</td><td style=\"text-align: right;\">       78.0 ± 0.0</td><td style=\"text-align: right;\">                  78.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">      78.0 ± 0.0</td><td style=\"text-align: right;\">    78.0 ± 0.0</td><td style=\"text-align: right;\">       78.0 ± 0.0</td><td style=\"text-align: right;\">                  78.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">     100.0 ± 0.0</td><td style=\"text-align: right;\">   100.0 ± 0.0</td><td style=\"text-align: right;\">      100.0 ± 0.0</td><td style=\"text-align: right;\">                 100.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">      0.06 ± 0.0</td><td style=\"text-align: right;\">    0.07 ± 0.0</td><td style=\"text-align: right;\">       0.09 ± 0.0</td><td style=\"text-align: right;\">                  0.06 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">           949.0</td><td style=\"text-align: right;\">         998.0</td><td style=\"text-align: right;\">           1000.0</td><td style=\"text-align: right;\">                       962.0</td></tr>\n</tbody>\n</table>",
      "application/papermill.record/text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "corridor40"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">     198.0 ± 0.0</td><td style=\"text-align: right;\">   198.0 ± 0.0</td><td style=\"text-align: right;\">      198.0 ± 0.0</td><td style=\"text-align: right;\">                 198.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">   195.25 ± 0.53</td><td style=\"text-align: right;\"> 195.78 ± 0.38</td><td style=\"text-align: right;\">      196.0 ± 0.0</td><td style=\"text-align: right;\">               195.67 ± 0.39</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">    98.63 ± 0.27</td><td style=\"text-align: right;\">   98.88 ± 0.2</td><td style=\"text-align: right;\">      98.98 ± 0.0</td><td style=\"text-align: right;\">                98.83 ± 0.21</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">      0.15 ± 0.0</td><td style=\"text-align: right;\">    0.16 ± 0.0</td><td style=\"text-align: right;\">       0.17 ± 0.0</td><td style=\"text-align: right;\">                  0.16 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">           228.0</td><td style=\"text-align: right;\">         222.0</td><td style=\"text-align: right;\">            329.0</td><td style=\"text-align: right;\">                       217.0</td></tr>\n</tbody>\n</table>",
      "application/papermill.record/text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "corridor100"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">      80.0 ± 0.0</td><td style=\"text-align: right;\">    80.0 ± 0.0</td><td style=\"text-align: right;\">       80.0 ± 0.0</td><td style=\"text-align: right;\">                  80.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">      80.0 ± 0.0</td><td style=\"text-align: right;\">    80.0 ± 0.0</td><td style=\"text-align: right;\">       80.0 ± 0.0</td><td style=\"text-align: right;\">                  80.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">     100.0 ± 0.0</td><td style=\"text-align: right;\">   100.0 ± 0.0</td><td style=\"text-align: right;\">      100.0 ± 0.0</td><td style=\"text-align: right;\">                 100.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">     0.73 ± 0.01</td><td style=\"text-align: right;\">   0.69 ± 0.01</td><td style=\"text-align: right;\">       1.32 ± 0.0</td><td style=\"text-align: right;\">                 0.72 ± 0.01</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">           459.0</td><td style=\"text-align: right;\">         440.0</td><td style=\"text-align: right;\">            377.0</td><td style=\"text-align: right;\">                       448.0</td></tr>\n</tbody>\n</table>",
      "application/papermill.record/text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "grid20"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">     160.0 ± 0.0</td><td style=\"text-align: right;\">   160.0 ± 0.0</td><td style=\"text-align: right;\">    161.67 ± 0.34</td><td style=\"text-align: right;\">                 160.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">     160.0 ± 0.0</td><td style=\"text-align: right;\">   160.0 ± 0.0</td><td style=\"text-align: right;\">    161.24 ± 0.24</td><td style=\"text-align: right;\">                 160.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">     100.0 ± 0.0</td><td style=\"text-align: right;\">   100.0 ± 0.0</td><td style=\"text-align: right;\">      100.0 ± 0.0</td><td style=\"text-align: right;\">                 100.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">     1.65 ± 0.02</td><td style=\"text-align: right;\">   1.63 ± 0.01</td><td style=\"text-align: right;\">      1.74 ± 0.01</td><td style=\"text-align: right;\">                 1.67 ± 0.02</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">           197.0</td><td style=\"text-align: right;\">         191.0</td><td style=\"text-align: right;\">            141.0</td><td style=\"text-align: right;\">                       216.0</td></tr>\n</tbody>\n</table>",
      "application/papermill.record/text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "grid40"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">                         </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">population of classifiers</td><td style=\"text-align: right;\">   404.67 ± 0.54</td><td style=\"text-align: right;\">  401.98 ± 0.3</td><td style=\"text-align: right;\">     409.1 ± 0.87</td><td style=\"text-align: right;\">                403.7 ± 0.57</td></tr>\n<tr><td style=\"text-align: right;\">     reliable classifiers</td><td style=\"text-align: right;\">     400.0 ± 0.0</td><td style=\"text-align: right;\">   400.0 ± 0.0</td><td style=\"text-align: right;\">    401.45 ± 0.25</td><td style=\"text-align: right;\">                 400.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">                knowledge</td><td style=\"text-align: right;\">     100.0 ± 0.0</td><td style=\"text-align: right;\">   100.0 ± 0.0</td><td style=\"text-align: right;\">      100.0 ± 0.0</td><td style=\"text-align: right;\">                 100.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">     trial execution time</td><td style=\"text-align: right;\">     3.24 ± 0.02</td><td style=\"text-align: right;\">   3.33 ± 0.02</td><td style=\"text-align: right;\">      3.35 ± 0.02</td><td style=\"text-align: right;\">                 3.23 ± 0.02</td></tr>\n<tr><td style=\"text-align: right;\">   average exploit reward</td><td style=\"text-align: right;\">            47.0</td><td style=\"text-align: right;\">          45.0</td><td style=\"text-align: right;\">             24.0</td><td style=\"text-align: right;\">                        17.0</td></tr>\n</tbody>\n</table>",
      "application/papermill.record/text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {
      "scrapbook": {
       "mime_prefix": "application/papermill.record/",
       "name": "grid100"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_models(dfs: Dict[str, pd.DataFrame], field: str, query_condition: str):\n",
    "    results = {}\n",
    "\n",
    "    for name, df in dfs.items():\n",
    "        data_arr = df.query(query_condition)[field].to_numpy()\n",
    "        bayes_model = bayes_estimate(data_arr)\n",
    "        results[name] = (bayes_model['mu'], bayes_model['std'])\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_average_reward(dfs: Dict[str, pd.DataFrame]):\n",
    "    results = {}\n",
    "\n",
    "    for name, df in dfs.items():\n",
    "        results[name] = df.query('phase == \"exploit\"')['reward'].mean()\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "experiments_data = {\n",
    "    'corridor20_eg': pd.concat(corridor20_eg_dfs),\n",
    "    'corridor40_eg': pd.concat(corridor40_eg_dfs),\n",
    "    'corridor100_eg': pd.concat(corridor100_eg_dfs),\n",
    "\n",
    "    'corridor20_ad': pd.concat(corridor20_ad_dfs),\n",
    "    'corridor40_ad': pd.concat(corridor40_ad_dfs),\n",
    "    'corridor100_ad': pd.concat(corridor100_ad_dfs),\n",
    "\n",
    "    'corridor20_ka': pd.concat(corridor20_ka_dfs),\n",
    "    'corridor40_ka': pd.concat(corridor40_ka_dfs),\n",
    "    'corridor100_ka': pd.concat(corridor100_ka_dfs),\n",
    "\n",
    "    'corridor20_oiq': pd.concat(corridor20_oiq_dfs),\n",
    "    'corridor40_oiq': pd.concat(corridor40_oiq_dfs),\n",
    "    'corridor100_oiq': pd.concat(corridor100_oiq_dfs),\n",
    "\n",
    "    'grid20_eg': pd.concat(grid20_eg_dfs),\n",
    "    'grid40_eg': pd.concat(grid40_eg_dfs),\n",
    "    'grid100_eg': pd.concat(grid100_eg_dfs),\n",
    "\n",
    "    'grid20_ad': pd.concat(grid20_ad_dfs),\n",
    "    'grid40_ad': pd.concat(grid40_ad_dfs),\n",
    "    'grid100_ad': pd.concat(grid100_ad_dfs),\n",
    "\n",
    "    'grid20_ka': pd.concat(grid20_ka_dfs),\n",
    "    'grid40_ka': pd.concat(grid40_ka_dfs),\n",
    "    'grid100_ka': pd.concat(grid100_ka_dfs),\n",
    "\n",
    "    'grid20_oiq': pd.concat(grid20_oiq_dfs),\n",
    "    'grid40_oiq': pd.concat(grid40_oiq_dfs),\n",
    "    'grid100_oiq': pd.concat(grid100_oiq_dfs)\n",
    "}\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/bayes/population.dill')\n",
    "def build_population_models(dfs: Dict[str, pd.DataFrame]):\n",
    "    return build_models(dfs, field='population', query_condition=f'trial == {explore_trials - 1}')\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/bayes/reliable.dill')\n",
    "def build_reliable_models(dfs: Dict[str, pd.DataFrame]):\n",
    "    return build_models(dfs, field='reliable', query_condition=f'trial == {explore_trials - 1}')\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/bayes/knowledge.dill')\n",
    "def build_knowledge_models(dfs: Dict[str, pd.DataFrame]):\n",
    "    return build_models(dfs, field='knowledge', query_condition=f'trial == {explore_trials - 1}')\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/bayes/perf_time.dill')\n",
    "def build_perf_time_models(dfs: Dict[str, pd.DataFrame]):\n",
    "    return build_models(dfs, field='perf_time', query_condition=f'phase == \"explore\"')\n",
    "\n",
    "\n",
    "population_models = build_population_models(experiments_data)\n",
    "reliable_models = build_reliable_models(experiments_data)\n",
    "knowledge_models = build_knowledge_models(experiments_data)\n",
    "perf_time_models = build_perf_time_models(experiments_data)\n",
    "avg_rewards = get_average_reward(experiments_data)\n",
    "\n",
    "\n",
    "def print_bayes_table(name_prefix, population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards):\n",
    "    print_row = lambda r: f'{round(r[0].mean(), 2)} ± {round(r[0].std(), 2)}'\n",
    "\n",
    "    key_names = [name for name in experiments_data.keys() if name.startswith(name_prefix)]\n",
    "\n",
    "    bayes_table_data = [\n",
    "        ['population of classifiers'] + [print_row(v) for name, v in population_models.items() if name in key_names],\n",
    "        ['reliable classifiers'] + [print_row(v) for name, v in reliable_models.items() if name in key_names],\n",
    "        ['knowledge'] + [print_row(v) for name, v in knowledge_models.items() if name in key_names],\n",
    "        ['trial execution time'] + [print_row(v) for name, v in perf_time_models.items() if name in key_names],\n",
    "        ['average exploit reward'] + [f'{round(v, 2)}' for name, v in avg_rewards.items() if name in key_names],\n",
    "    ]\n",
    "\n",
    "    table = tabulate(bayes_table_data,\n",
    "                     headers=['', 'Epsilon Greedy', 'Action Delay', 'Knowledge Array', 'Optimistic Initial Quality'],\n",
    "                     tablefmt=\"html\",\n",
    "                     stralign='right')\n",
    "    return HTML(table)\n",
    "\n",
    "# Add glue for rendering output in tabs\n",
    "glue(\"corridor20\", print_bayes_table('corridor20', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards), display=False)\n",
    "glue(\"corridor40\", print_bayes_table('corridor40', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards), display=False)\n",
    "glue(\"corridor100\", print_bayes_table('corridor100', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards), display=False)\n",
    "glue(\"grid20\", print_bayes_table('grid20', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards), display=False)\n",
    "glue(\"grid40\", print_bayes_table('grid40', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards), display=False)\n",
    "glue(\"grid100\", print_bayes_table('grid100', population_models, reliable_models, knowledge_models, perf_time_models, avg_rewards), display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Corridor\n",
    "```{tabbed} Corridor 20\n",
    "{glue:}`corridor20`\n",
    "```\n",
    "\n",
    "```{tabbed} Corridor 40\n",
    "{glue:}`corridor40`\n",
    "```\n",
    "\n",
    "```{tabbed} Corridor 100\n",
    "{glue:}`corridor100`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Grid\n",
    "```{tabbed} Grid 20\n",
    "{glue:}`grid20`\n",
    "```\n",
    "\n",
    "```{tabbed} Grid 40\n",
    "{glue:}`grid40`\n",
    "```\n",
    "\n",
    "```{tabbed} Grid 100\n",
    "{glue:}`grid100`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Observations\n",
    "\n",
    "**Corridor**\n",
    "\n",
    "Based on the Figure {numref}`{number} <41-e2-corridor-fig>` all methods converge to optimal population size, and after switching to the exploitation mode, can utilize gained knowledge fully. Regardless of the exploration technique chosen, the agent can obtain complete knowledge of the environment in about 20 trials. AD and KA techniques seem to reach this point faster than the baseline EG and with OIQ modification.\n",
    "\n",
    "The AD and KA methods accelerate the process of investigating the search-space resulting in earlier classifier creation.\n",
    "\n",
    "Finally, the agent can fully exploit the environment after switching to \"exploit\" mode performing a minimal number of steps to reach the goal in each trial. Its also worth mentioning the constant effect of the KA method in explore phase, not taking the optimal actions most of the time, by continually updating the assumptions about all possibilities.\n",
    "\n",
    "However, when the problem size increased twice ($n=40$), while all strategies obtained full knowledge of the environment, only the KA method managed to exploit it totally unerringly. This difference is highlighted more for $n=100$, where only about a third of all exploit trials were successful by KA, and other strategies performed significantly worse.\n",
    "\n",
    "**Grid**\n",
    "\n",
    "Performance plot using Grid of size $n=20$ in Figure {numref}`{number} <41-e2-grid-fig>` shows that regardless of exploration technique chosen, the agent is still able to obtain full knowledge of the environment (even faster than in Corridor) and converge with the number of optimal classifiers (KA method here also creates much more classifiers at the beginning of the experimentation).\n",
    "\n",
    "Interestingly, the KA obtains the worst average reward despite having the largest amount of reliable classifiers for problems where $n=20$ and $n=40$.\n",
    "\n",
    "Moreover, what is interesting is that the agent cannot exploit the environment even though he knows the exact consequences of each action (non-optimal number of steps in the exploitation phase). After investigation, it was found that most classifiers have a very similar $cl.r$ value, representing the expected future reward. The agent in the current form is unable to differentiate between aliasing states, resulting in an inability to form an optimal policy. This finding emphasizes a need for a universal metric for quantifying the agent's performance. The current definition of knowledge, modelling only encountered transitions, is inaccurate when the estimated reward is not distributed correctly amongst participating classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Software packages used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "gym                 0.21.0\n",
       "gym_corridor        NA\n",
       "lcs                 NA\n",
       "matplotlib          3.5.1\n",
       "myst_nb             0.13.1\n",
       "pandas              1.4.0\n",
       "pydev_jupyter_utils NA\n",
       "pydev_jupyter_vars  NA\n",
       "session_info        1.0.0\n",
       "src                 (embedded book's utils module)\n",
       "tabulate            0.8.9\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                 8.4.0\n",
       "arviz               0.11.2\n",
       "asttokens           NA\n",
       "attr                21.4.0\n",
       "babel               2.9.1\n",
       "backcall            0.2.0\n",
       "beta_ufunc          NA\n",
       "binom_ufunc         NA\n",
       "brotli              NA\n",
       "cachetools          5.0.0\n",
       "certifi             2021.10.08\n",
       "cffi                1.15.0\n",
       "cftime              1.5.2\n",
       "charset_normalizer  2.0.10\n",
       "click               7.1.2\n",
       "cloudpickle         2.0.0\n",
       "colorama            0.4.4\n",
       "colorful            0.5.4\n",
       "colorful_orig       0.5.4\n",
       "cryptography        36.0.1\n",
       "cycler              0.10.0\n",
       "cython_runtime      NA\n",
       "databricks_cli      NA\n",
       "dateutil            2.8.2\n",
       "debugpy             1.5.1\n",
       "decorator           5.1.1\n",
       "defusedxml          0.7.1\n",
       "dill                0.3.4\n",
       "docutils            0.16\n",
       "entrypoints         0.3\n",
       "executing           0.8.2\n",
       "fastprogress        0.2.7\n",
       "filelock            3.4.2\n",
       "google              NA\n",
       "greenlet            1.1.2\n",
       "grpc                1.43.0\n",
       "hiredis             2.0.0\n",
       "idna                3.3\n",
       "imagesize           NA\n",
       "importlib_metadata  NA\n",
       "ipykernel           6.7.0\n",
       "ipython_genutils    0.2.0\n",
       "ipywidgets          7.6.5\n",
       "jedi                0.18.1\n",
       "jinja2              3.0.3\n",
       "jsonschema          3.2.0\n",
       "jupyter_cache       0.4.3\n",
       "jupyter_sphinx      0.3.2\n",
       "jupyterlab_pygments 0.1.2\n",
       "kiwisolver          1.3.2\n",
       "linkify_it          1.0.3\n",
       "markdown_it         1.1.0\n",
       "markupsafe          2.0.1\n",
       "matplotlib_inline   NA\n",
       "mdit_py_plugins     0.2.8\n",
       "mistune             0.8.4\n",
       "mlflow              1.23.1\n",
       "mpl_toolkits        NA\n",
       "msgpack             1.0.3\n",
       "myst_parser         0.15.2\n",
       "nbclient            0.5.10\n",
       "nbconvert           6.4.1\n",
       "nbformat            5.1.3\n",
       "nbinom_ufunc        NA\n",
       "netCDF4             1.5.8\n",
       "numpy               1.22.1\n",
       "packaging           21.3\n",
       "pandocfilters       NA\n",
       "parso               0.8.3\n",
       "pexpect             4.8.0\n",
       "pickleshare         0.7.5\n",
       "pkg_resources       NA\n",
       "prompt_toolkit      3.0.26\n",
       "psutil              5.9.0\n",
       "ptyprocess          0.7.0\n",
       "pure_eval           0.2.2\n",
       "pvectorc            NA\n",
       "pydevconsole        NA\n",
       "pydevd_file_utils   NA\n",
       "pydevd_plugins      NA\n",
       "pygments            2.11.2\n",
       "pylab               NA\n",
       "pymc3               3.11.4\n",
       "pyparsing           3.0.7\n",
       "pyrsistent          NA\n",
       "pytz                2021.3\n",
       "ray                 1.9.2\n",
       "redis               4.1.2\n",
       "requests            2.27.1\n",
       "scipy               1.7.3\n",
       "semver              2.13.0\n",
       "setproctitle        1.2.2\n",
       "setuptools          60.5.0\n",
       "six                 1.16.0\n",
       "socks               1.7.1\n",
       "sphinx              4.4.0\n",
       "sphinxcontrib       NA\n",
       "sqlalchemy          1.4.31\n",
       "stack_data          0.1.4\n",
       "testpath            0.5.0\n",
       "theano              1.1.2\n",
       "tornado             6.1\n",
       "tqdm                4.62.3\n",
       "traitlets           5.1.1\n",
       "typing_extensions   NA\n",
       "uc_micro            1.0.1\n",
       "unicodedata2        NA\n",
       "urllib3             1.26.8\n",
       "wcwidth             0.2.5\n",
       "xarray              0.21.0\n",
       "yaml                6.0\n",
       "zipp                NA\n",
       "zmq                 22.3.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             8.0.1\n",
       "jupyter_client      7.1.2\n",
       "jupyter_core        4.9.1\n",
       "notebook            6.4.8\n",
       "-----\n",
       "Python 3.9.10 | packaged by conda-forge | (main, Jan 28 2022, 19:23:19) [GCC 9.4.0]\n",
       "Linux-5.13.0-27-generic-x86_64-with-glibc2.31\n",
       "-----\n",
       "Session information updated at 2022-01-30 14:34\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}