{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<matplotlib.pyplot._IoffContext at 0x7fe4f04054f0>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gym\n",
    "import gym_maze  # noqa: F401\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pathlib\n",
    "import random\n",
    "from itertools import groupby\n",
    "\n",
    "from src.decorators import get_from_cache_or_run\n",
    "from lcs import Perception\n",
    "\n",
    "from src.visualization import PLOT_DPI\n",
    "from src.utils import build_plots_dir_path, build_cache_dir_path\n",
    "\n",
    "root_dir = pathlib.Path().cwd().parent.parent.parent\n",
    "cwd_dir_name = pathlib.Path().cwd().name\n",
    "\n",
    "plot_dir = build_plots_dir_path(root_dir) / cwd_dir_name\n",
    "cache_dir = build_cache_dir_path(root_dir) / cwd_dir_name\n",
    "\n",
    "plt.ioff();  # turn off interactive plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Road towards Anticipatory Learning Classifier Systems\n",
    "The concept of LCS was introduced by John Holland in 1975 {cite}`holland1975adaptation` in order to model the idea of cognition based on adaptive mechanisms. From the early days they consist of a set of rules named _classifiers_  combined with mechanisms in charge of evolving them. Initially the goal was to handle problems related to online interaction with external environments, as described by Wilson in {cite}`wilson1986knowledge`.\n",
    "\n",
    "To accomplish this, the emphasis was put on parallelism in the architecture and evolutionary mechanisms allowing the agent to adapt to potentially changing environment {cite}`goldberg1988genetic`. This approach was referenced as _\"escaping brittleness\"_ {cite}`holland1986escaping` due to the problems related to the lack of robustness of the current artificial intelligence systems.\n",
    "\n",
    "`````{margin}\n",
    "````{admonition} John Holland\n",
    "```{image} ../../_static/John_Holland.jpg\n",
    "```\n",
    "\n",
    "**John Henry Holland** (February 2, 1929 – August 9, 2015) was an American scientist and Professor of psychology and Professor of electrical engineering and computer science at the University of Michigan, Ann Arbor.\n",
    "\n",
    "He was a pioneer in what became known as genetic algorithms.\n",
    "````\n",
    "`````\n",
    "\n",
    "The naming convention used to refer to the LCS algorithm also changed since its infancy. Holland initially called it as a classifier system, abbreviated either as (CS) or (CFS) {cite}`robertson1988tale`. From that time it was also referred to as adaptive agents {cite}`holland1996hidden`, cognitive systems {cite}`holland1978cognitive` and genetic-based machine learning {cite}`dam2007neural` {cite}`goldberg1989`. The current name of LCS was not adopted until the late 80s {cite}`riolo1988empirical` after extending the architecture with a credit assignment component {cite}`holland1986escaping` {cite}`holland1986mathematical`.\n",
    "\n",
    "This section provides a synopsis of crucial LCS concepts alongside the most popular variants, and the contributions they made to the field.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Selected topics of LCS\n",
    "### Rules and Classifiers\n",
    "\n",
    "In general form, LCS utilizes _rules_ as a fundamental block of modeling knowledge. It comprises a _condition_ (i.e. specified feature states), and an _action_ (also referred to as the class). They can be interpreted using the \"IF condition THEN action\" logical expression. When the condition part is expressed with either boolean or nominal representation the generalization property using the \"don't care\" symbol # is possible. Two input situations are considered equivalent with respect to a given classifier if the specified (non-#) values in the condition match the corresponding attributes of the two situations\n",
    "\n",
    "In addition to condition and action, a rule typically has a number of algorithm related parameter values associated with it (like its performance or expected reward). The term _classifier_ is used to describe a rule along with it associated parameters.\n",
    "\n",
    "It is important to realise that LCS comprise a population of single rules, that collaboratively seek to cover the problem space. The number of classifiers needed to solve the particular problem depends on a number of factors like problem complexity or rule representation used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Driving Mechanisms\n",
    "There are two fundamental components behind every LCS algorithm - the discovery and learning (credit assignment) component. Both of them have generated respective fields of study, but it is in the context of LCS that we wish to understand their function and purpose.\n",
    "\n",
    "**Discovery component**\n",
    "\n",
    "The discovery component is responsible for exploring the search space of the target problem with the purpose of discovering new rules. A vast majority of LCS algorithms employ some form of Evolutionary Computation, most often Genetic Algorithm (GA), employing Neo-Darwinist theory of natural selection {cite}`bull2005foundations` {cite}`goldberg1989`. The evolution of rules is modeled after the evolution of organisms using following biological analogies:\n",
    "\n",
    "1. a code is used to represent the genotype/genome (condition),\n",
    "2. a solution (phenotype) representation is associated with that genome (action),\n",
    "3. a phenotype selection process (survival of the fittest) - the fittest organism (rule) has the greatest chances of reproducing and passing parts of its genome to offsprings,\n",
    "4. certain genetic genome operators are utilized in order to chase after fitter organisms (rules) {cite}`sigaud2007learning` {cite}`holmes1999learning`.\n",
    "\n",
    "Two genetic operators are typically used to alternate genome (rule) - mutation and crossover (recombination). The first one randomly modify an element in a genotype of an individual (rule), while the latter one recombine parts of two promising genotypes (rules) creating a new one. The selection pressure driving better organisms (rules) to reproduce more frequently depends on the fitness function. The fitness function quantifies the optimality of given rule, allowing it to be ranked across all rules in entire population.\n",
    "\n",
    "GA implementation varies in certain LCS, but the overall scheme involves evaluating all available rules, selecting most promising offsprings (according to fitness value), applying genetic operators, introducing new offspring back to population set and finally removing excess or under-performing individuals.\n",
    "\n",
    "\n",
    "**Learning component**\n",
    "\n",
    "As mentioned earlier each classifier is accompanied by certain parameter values. The iterative update of them drives the process of LCS reinforcement by distributing any incoming reward signal to the classifiers that are accountable for it. This process serves two purposes:\n",
    "\n",
    "1. identification of classifiers responsible for obtaining large future rewards,\n",
    "2. encourage the discoverability of new rules (by directly affecting the fitness value)\n",
    "\n",
    "The learning strategy depends on the nature of the problem and is realized differently in LCS implementations. In all cases, however the process is performed through trial-and-error interactions with the environment, where occasional immediate reward is used to generate the policy (state-action mapping of agent-environment interactions) maximizing long-term reward {cite}`sutton2018reinforcement` {cite}`harmon96reinforcementlearning` {cite}`richter2003reinforcement`.\n",
    "\n",
    "\n",
    "### Functional cycle\n",
    "The agent interacts with the environment in consecutive trials. Each trial consists of sequential steps usually executed as follows:\n",
    "\n",
    "1. Filter population $[P]$ and select classifiers where condition matches environmental perception forming a _match-set_ $[M]$.\n",
    "2. Determine action that will be executed (depending on the strategy).\n",
    "3. Narrow-down the match-set by selecting only classifiers advocating proposed action.\n",
    "4. Execute the action in the environment obtaining a new state\n",
    "5. Refine classifiers by executing discovery and learning components.\n",
    "\n",
    "The action selection and classifiers evolution phases are implemented individually in different LCS, but the main objective of reaching ideal generalization level is crucial to all of them. The system should find a population that covers the search space as compactly as possible without being detrimental to the optimality of behavior.\n",
    "\n",
    "### Pittsburgh vs Michigan\n",
    "One of the most fundamental distinction in LSC research is the way of storing knowledge by using two different approaches - _Michigan-style_ or _Pittsburgh-style_. The first ones were proposed by Holland {cite}`holland1978cognitive` while the latter one by Kenneth DeJong and his student {cite}`smith1980learning` {cite}`smith1983flexible`.\n",
    "\n",
    "The fundamental distinction is the structure of an individual. In Michigan systems each individual is a classifier, in Pittsburgh each individual is a set of classifiers - see Figure {numref}`{number} <michigan-pittsburgh-fig>`.\n",
    "\n",
    ":::{figure-md} michigan-pittsburgh-fig\n",
    "<img src=\"../../_static/michigan_pittsburgh.png\">\n",
    "\n",
    "Differences between representing knowledge in both Michigan-style and Pittsburgh-style LCS. Figure taken from {cite}`bacardit2006learning`.\n",
    ":::\n",
    "\n",
    "Therefore, the classifiers in Michigan-style LCS are being continuously evaluated and evolved, while in Pittsburgh-style LCS the same process is much more complicated because the whole population needs to be assessed. Thus, Michigan-style systems are typically applied in interactive, online learning problems, while Pittsburgh ones are rather suitable for offline learning {cite}`bacardit2006learning`. This work focuses on the first class of LCS."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Representative Michigan-style LCS"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### CS-1\n",
    "Two years after presenting the theoretical model of CS Holland and Reitman proposed its implementation CS-1 {cite}`holland1978cognitive`. The system realized the Darwinian principle of the survival of the fittest and was generating adaptive behaviour by maximizing reinforcement using the bucket brigade algorithm {cite}`holland1989induction`. Some internal mechanisms like the usage of a message list or interactions between evolving both single classifier and entire population were considered difficult {cite}`wilson1989critical` which signifies the need for improvements.\n",
    "\n",
    "### ZCS\n",
    "`````{margin}\n",
    "````{admonition} Steward Wilson\n",
    "```{image} ../../_static/steward_wilson.gif\n",
    "```\n",
    "\n",
    "[link](https://ieeexplore.ieee.org/author/37550361200)\n",
    "````\n",
    "`````\n",
    "The _Zeroth Level Classifier_ (ZCS) introduced by Wilson in 1994 {cite}`wilson1994zcs` encompasses all LCS components while simplifying the CS-1 increasing its understandability and performance. The major changes was the removing of the internal message list (determining the rule's format entirely by the system interface) alongside with rule-bidding credit assignment (replacing it with Q-learning {cite}`watkins1989learning`).\n",
    "\n",
    "Moreover, the classifier fitness was based on the accumulated reward that the agent can get from firing the classifier which gave rise to the _\"strength-based\"_ family of LCS. As a result the discovery component eliminates classifiers providing less reward than others from the population.\n",
    "\n",
    "This premature converge onto suboptimal rules before space can be properly explores and stable population formed led Wilson to consider other ways in which this might be achieved.\n",
    "\n",
    "(section-topics-history-xcs)=\n",
    "### XCS\n",
    "[wiki](https://en.wikipedia.org/wiki/Learning_classifier_system)\n",
    "XCS {cite}`wilson1995classifier` {cite}`wilson1998generalization` {cite}`wilson1999state`\n",
    "\n",
    "XCS uses niche-GA [Booker, 1985] meaning that GA acts in the action space $[A]$, instead of globally."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Anticipatory Learning Classifier Systems\n",
    "### ACS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import lcs.agents.acs2 as acs2\n",
    "from lcs.metrics import population_metrics\n",
    "\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "def maze_metrics(agent, env):\n",
    "    metrics = {}\n",
    "    metrics.update(population_metrics(agent.population, env))\n",
    "    return metrics\n",
    "\n",
    "acs2_base_params = {\n",
    "    'classifier_length': 8,\n",
    "    'number_of_possible_actions': 8,\n",
    "    'biased_exploration': 0,\n",
    "    'metrics_trial_frequency': 1,\n",
    "    'user_metrics_collector_fcn': maze_metrics\n",
    "}\n",
    "\n",
    "def run_acs2_explore_exploit(env, explore_trials, exploit_trials, **config):\n",
    "    cfg = acs2.Configuration(**config)\n",
    "\n",
    "    # explore phase\n",
    "    agent = acs2.ACS2(cfg)\n",
    "    metrics_explore = agent.explore(env, explore_trials)\n",
    "\n",
    "    # exploit phase\n",
    "    agent_exploit = acs2.ACS2(cfg, copy(agent.population))\n",
    "    metrics_exploit = agent_exploit.exploit(env, exploit_trials)\n",
    "\n",
    "    return (agent, metrics_explore), (agent_exploit, metrics_exploit)\n",
    "\n",
    "def find_best_classifier(population: acs2.ClassifiersList, situation: Perception) -> Optional[acs2.Classifier]:\n",
    "    match_set = population.form_match_set(situation)\n",
    "    anticipated_change_cls = [cl for cl in match_set if cl.does_anticipate_change()]\n",
    "\n",
    "    if len(anticipated_change_cls) > 0:\n",
    "        return max(anticipated_change_cls, key=lambda cl: cl.fitness)\n",
    "\n",
    "    return None\n",
    "\n",
    "def build_fitness_and_action_matrices(env, population) -> Tuple:\n",
    "    original = env.env.maze.matrix\n",
    "\n",
    "    fitness = original.copy()\n",
    "    action = original.copy().astype(str)\n",
    "\n",
    "    action_lookup = {\n",
    "        0: u'↑', 1: u'↗', 2: u'→', 3: u'↘',\n",
    "        4: u'↓', 5: u'↙', 6: u'←', 7: u'↖'\n",
    "    }\n",
    "\n",
    "    for index, x in np.ndenumerate(original):\n",
    "        if x == 0:  # path\n",
    "            perception = env.env.maze.perception(index)\n",
    "            best_cl = find_best_classifier(population, perception)\n",
    "\n",
    "            if best_cl:\n",
    "                fitness[index] = best_cl.fitness\n",
    "                action[index] = action_lookup[best_cl.action]\n",
    "            else:\n",
    "                fitness[index] = -1\n",
    "                action[index] = '?'\n",
    "\n",
    "        if x == 1:  # wall\n",
    "            fitness[index] = 0\n",
    "            action[index] = '\\#'\n",
    "\n",
    "        if x == 9:  # reward\n",
    "            # add 500 to make it more distinguishable\n",
    "            fitness[index] = fitness.max() + 500\n",
    "            action[index] = 'R'\n",
    "\n",
    "    return fitness, action\n",
    "\n",
    "def plot_policy(env, fitness_matrix, action_matrix):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(14, 8))\n",
    "\n",
    "    max_x, max_y = env.env.maze.matrix.shape\n",
    "\n",
    "    # Render maze as image\n",
    "    plt.imshow(fitness_matrix, interpolation='nearest', cmap='Reds', aspect='auto', extent=[0, max_x, max_y, 0])\n",
    "\n",
    "    # Add labels to each cell\n",
    "    for (y, x), val in np.ndenumerate(action_matrix):\n",
    "        plt.text(x + 0.4, y + 0.5, \"${}$\".format(val))\n",
    "\n",
    "    ax.set_title(\"Policy in Maze5 environment\", fontsize=24)\n",
    "    ax.set_xlabel('x', fontsize=18)\n",
    "    ax.set_ylabel('y', fontsize=18)\n",
    "    ax.set_xlim(0, max_x)\n",
    "    ax.set_ylim(max_y, 0)\n",
    "    ax.set_xticks(range(0, max_x))\n",
    "    ax.set_yticks(range(0, max_y))\n",
    "    ax.grid(True)\n",
    "    fig.savefig(f'{plot_dir}/acs2-maze5-policy.png', dpi=PLOT_DPI)\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/acs2_maze5.dill')\n",
    "def run_acs2_in_maze5():\n",
    "    env = gym.make('Maze5-v0')\n",
    "    explore_phase, exploit_phase = run_acs2_explore_exploit(env, explore_trials=5000, exploit_trials=100, **acs2_base_params)\n",
    "    return env, explore_phase, exploit_phase\n",
    "\n",
    "# Run computation\n",
    "env_, explore_, exploit_ = run_acs2_in_maze5()\n",
    "\n",
    "# Plot the policy\n",
    "fitness_matrix, action_matrix = build_fitness_and_action_matrices(env_, explore_[0].population)\n",
    "plot_policy(env_, fitness_matrix, action_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ":::{figure-md} maze5-fig\n",
    ":class: full-width\n",
    "<img src=\"../../_static/plots/2_selected_topics/acs2-maze5-policy.png\">\n",
    "\n",
    "Policy of Maze5. Saturation of red color reflects the best classifier fitness value.\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### MACS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m\n",
      "\u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[30m■\u001B[0m\n",
      "\u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[30m■\u001B[0m\n",
      "\u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[30m■\u001B[0m\n",
      "\u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[30m■\u001B[0m\n",
      "\u001B[30m■\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[37m□\u001B[0m \u001B[31mA\u001B[0m \u001B[33m$\u001B[0m \u001B[30m■\u001B[0m\n",
      "\u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m \u001B[30m■\u001B[0m\n",
      "Perception: 009111000\n"
     ]
    }
   ],
   "source": [
    "import lcs.agents.macs.macs as macs\n",
    "\n",
    "maze228_env = gym.make('Maze228-v0')\n",
    "\n",
    "def _calculate_rotating_maze_knowledge(agent: macs.MACS, env):\n",
    "    transitions = env.env.transitions\n",
    "    covered_transitions = 0\n",
    "\n",
    "    for p0, a, p1 in transitions:\n",
    "        p0p = Perception(list(map(str, p0)))\n",
    "        p1p = Perception(list(map(str, p1)))\n",
    "        anticipations = list(agent.get_anticipations(p0p, a))\n",
    "\n",
    "        # accurate classifiers\n",
    "        if len(anticipations) == 1 and anticipations[0] == p1p:\n",
    "            covered_transitions += 1\n",
    "\n",
    "    return covered_transitions / len(transitions)\n",
    "\n",
    "def _macs_metrics(agent: macs.MACS, env):\n",
    "    population = agent.population\n",
    "    return {\n",
    "        'pop': len(population),\n",
    "        'situations': len(agent.desirability_values),\n",
    "        '0_cls': len([cl for cl in population if cl.action == 0 and cl.is_accurate]),\n",
    "        '1_cls': len([cl for cl in population if cl.action == 1 and cl.is_accurate]),\n",
    "        '2_cls': len([cl for cl in population if cl.action == 2 and cl.is_accurate]),\n",
    "        'knowledge': _calculate_rotating_maze_knowledge(agent, env)\n",
    "    }\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/macs_maze228.dill')\n",
    "def run_macs_in_maze228(env):\n",
    "    cfg = macs.Configuration(classifier_length=9,\n",
    "                        number_of_possible_actions=3,\n",
    "                        feature_possible_values=[{'0', '1', '9'}] * 8 + [{'0', '9'}],\n",
    "                        estimate_expected_improvements=True,\n",
    "                        metrics_trial_frequency=10,\n",
    "                        user_metrics_collector_fcn=_macs_metrics)\n",
    "\n",
    "    agent = macs.MACS(cfg)\n",
    "    metrics = agent.explore(env, 100)\n",
    "\n",
    "    return agent, metrics\n",
    "\n",
    "# run computations\n",
    "macs_agent, macs_metrics = run_macs_in_maze228(maze228_env)\n",
    "\n",
    "# visualization\n",
    "random.seed(129)  # found experimentally\n",
    "maze228_env.reset()\n",
    "maze228_env.render()\n",
    "\n",
    "left_from_reward = maze228_env.env.maze.perception()\n",
    "\n",
    "print(f'Perception: {\"\".join(left_from_reward)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MACS population size: 211\n",
      "\n",
      "Action: STEP_AHEAD, anticipation: [0 0 0 9 0 0 0 1 0]\n",
      "\t0#9###### 0 0????????\n",
      "\t#0###10## 0 ?0???????\n",
      "\t0#9##1### 0 ?0???????\n",
      "\t#0####### 0 ??0??????\n",
      "\t0#9###### 0 ???9?????\n",
      "\t0######## 0 ????0????\n",
      "\t0#####0## 0 ?????0???\n",
      "\t#######0# 0 ??????0??\n",
      "\t##9###### 0 ??????0??\n",
      "\t##91#10## 0 ???????1?\n",
      "\t0######## 0 ????????0\n",
      "\n",
      "Action: ROTATE_LEFT, anticipation: [0 0 0 0 9 1 1 1 0]\n",
      "\t######0## 1 0????????\n",
      "\t#######0# 1 ?0???????\n",
      "\t0######## 1 ??0??????\n",
      "\t#0####### 1 ???0?????\n",
      "\t##9###### 1 ????9????\n",
      "\t###1##### 1 ?????1???\n",
      "\t####1#### 1 ??????1??\n",
      "\t#####1### 1 ???????1?\n",
      "\t######### 1 ????????0\n",
      "\n",
      "Action: ROTATE_RIGHT, anticipation: [9 1 1 1 0 0 0 0 0]\n",
      "\t##9###### 2 9????????\n",
      "\t###1##### 2 ?1???????\n",
      "\t####1#### 2 ??1??????\n",
      "\t#####1### 2 ???1?????\n",
      "\t######0## 2 ????0????\n",
      "\t#######0# 2 ?????0???\n",
      "\t0######## 2 ??????0??\n",
      "\t#0####### 2 ???????0?\n",
      "\t######### 2 ????????0\n"
     ]
    }
   ],
   "source": [
    "print(f'Total MACS population size: {len(macs_agent.population)}')\n",
    "s = sorted(macs_agent.population.form_match_set(left_from_reward), key=lambda cl: cl.action)\n",
    "\n",
    "action_mapping = ['STEP_AHEAD', 'ROTATE_LEFT', 'ROTATE_RIGHT']\n",
    "\n",
    "for action, group_cl in groupby(s, key=lambda cl: cl.action):\n",
    "    print(f'\\nAction: {action_mapping[action]}, anticipation: {list((macs_agent.get_anticipations(left_from_reward, action)))}')\n",
    "    for cl in sorted(group_cl, key=lambda cl: cl.effect):\n",
    "        print(f'\\t{cl.condition} {cl.action} {cl.effect}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Comparing the ACS2 agent in the same environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def _acs2_metrics(agent: acs2.ACS2, env):\n",
    "    population = agent.population\n",
    "    reliable = [cl for cl in population if cl.is_reliable()]\n",
    "    return {\n",
    "        'pop': len(population),\n",
    "        'rel': len(reliable)\n",
    "    }\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/acs2_maze228.dill')\n",
    "def run_acs2_in_maze228(env):\n",
    "    cfg = acs2.Configuration(classifier_length=9,\n",
    "                        number_of_possible_actions=3,\n",
    "                        metrics_trial_frequency=1,\n",
    "                        user_metrics_collector_fcn=_acs2_metrics,\n",
    "                        do_ga=False)\n",
    "\n",
    "    agent = acs2.ACS2(cfg)\n",
    "    metrics = agent.explore(env, 5000)\n",
    "\n",
    "    return agent, metrics\n",
    "\n",
    "acs2_agent, acs2_metrics = run_acs2_in_maze228(maze228_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reliable population for ACS2: 402\n",
      "##911#00# 1 ##009#11#\n",
      "##9111#0# 0 ##0900#1#\n",
      "009#11### 2 911#00###\n"
     ]
    }
   ],
   "source": [
    "reliable_classifiers = [cl for cl in acs2_agent.population if cl.is_reliable()]\n",
    "\n",
    "print(f'Total reliable population for ACS2: {len(reliable_classifiers)}')\n",
    "for cl in acs2_agent.population.form_match_set(left_from_reward):\n",
    "    if cl.is_reliable():\n",
    "        print(f'{cl.condition} {cl.action} {cl.effect}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Software packages used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<details>\n<summary>Click to view session information</summary>\n<pre>\n-----\ngym                 0.21.0\ngym_maze            NA\nlcs                 NA\nmatplotlib          3.5.1\nnumpy               1.22.1\npandas              1.4.0\npydev_jupyter_utils NA\npydev_jupyter_vars  NA\nsession_info        1.0.0\nsrc                 (embedded book's utils module)\n-----\n</pre>\n<details>\n<summary>Click to view modules imported as dependencies</summary>\n<pre>\nPIL                 8.4.0\nasttokens           NA\nbackcall            0.2.0\nbrotli              NA\ncertifi             2021.10.08\ncffi                1.15.0\ncharset_normalizer  2.0.10\nclick               7.1.2\ncloudpickle         2.0.0\ncolorama            0.4.4\ncolorful            0.5.4\ncolorful_orig       0.5.4\ncryptography        36.0.1\ncycler              0.10.0\ncython_runtime      NA\ndatabricks_cli      NA\ndateutil            2.8.2\ndebugpy             1.5.1\ndecorator           5.1.1\ndefusedxml          0.7.1\ndill                0.3.4\nentrypoints         0.3\nexecuting           0.8.2\nfilelock            3.4.2\ngoogle              NA\ngrpc                1.43.0\nhiredis             2.0.0\nidna                3.3\nimportlib_metadata  NA\nipykernel           6.7.0\nipython_genutils    0.2.0\njedi                0.18.1\nkiwisolver          1.3.2\nlxml                4.7.1\nmatplotlib_inline   NA\nmlflow              1.23.1\nmpl_toolkits        NA\nmsgpack             1.0.3\nnetworkx            2.5\npackaging           21.3\nparso               0.8.3\npexpect             4.8.0\npickleshare         0.7.5\npkg_resources       NA\nprompt_toolkit      3.0.26\npsutil              5.9.0\nptyprocess          0.7.0\npure_eval           0.2.2\npydevconsole        NA\npydevd_file_utils   NA\npydevd_plugins      NA\npygments            2.11.2\npylab               NA\npyparsing           3.0.7\npytz                2021.3\nray                 1.9.2\nredis               4.1.2\nrequests            2.27.1\nscipy               1.7.3\nsetproctitle        1.2.2\nsetuptools          60.5.0\nsix                 1.16.0\nsocks               1.7.1\nsphinxcontrib       NA\nstack_data          0.1.4\ntornado             6.1\ntqdm                4.62.3\ntraitlets           5.1.1\ntyping_extensions   NA\nunicodedata2        NA\nurllib3             1.26.8\nwcwidth             0.2.5\nyaml                6.0\nzipp                NA\nzmq                 22.3.0\n</pre>\n</details> <!-- seems like this ends pre, so might as well be explicit -->\n<pre>\n-----\nIPython             8.0.1\njupyter_client      7.1.2\njupyter_core        4.9.1\nnotebook            6.4.8\n-----\nPython 3.9.10 | packaged by conda-forge | (main, Jan 28 2022, 19:23:19) [GCC 9.4.0]\nLinux-5.13.0-27-generic-x86_64-with-glibc2.31\n-----\nSession information updated at 2022-01-30 13:38\n</pre>\n</details>"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import session_info\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}