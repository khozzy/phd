{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import HTML\n",
    "from lcs.agents.acs2 import Configuration, ACS2\n",
    "from lcs.metrics import population_metrics\n",
    "from lcs.strategies.action_selection import EpsilonGreedy, ActionDelay, KnowledgeArray\n",
    "from myst_nb import glue\n",
    "from tabulate import tabulate\n",
    "\n",
    "from src.bayes_estimation import bayes_estimate\n",
    "from src.decorators import repeat, get_from_cache_or_run\n",
    "from src.metrics import parse_experiments_results\n",
    "from src.utils import build_plots_dir_path, build_cache_dir_path\n",
    "from src.visualization import biased_exploration_colors, PLOT_DPI\n",
    "\n",
    "COLORS = biased_exploration_colors()\n",
    "\n",
    "plt.ioff()  # turn off interactive plotting\n",
    "\n",
    "root_dir = pathlib.Path().cwd().parent.parent.parent\n",
    "cwd_dir = pathlib.Path().cwd()\n",
    "\n",
    "plot_dir = build_plots_dir_path(root_dir) /  cwd_dir.name\n",
    "cache_dir = build_cache_dir_path(root_dir) /  cwd_dir.name\n",
    "\n",
    "\n",
    "def run_experiment(env_provider, explore_trials, exploit_trials, **conf):\n",
    "    env = env_provider()\n",
    "    env.reset()\n",
    "\n",
    "    cfg = Configuration(**conf)\n",
    "\n",
    "    explorer = ACS2(cfg)\n",
    "    metrics_explore = explorer.explore(env, explore_trials)\n",
    "\n",
    "    exploiter = ACS2(cfg, explorer.population)\n",
    "    metrics_exploit = explorer.exploit(env, exploit_trials)\n",
    "\n",
    "    # Parse results into DataFrame\n",
    "    metrics_df = parse_experiments_results(metrics_explore, metrics_exploit, cfg.metrics_trial_frequency)\n",
    "\n",
    "    return metrics_df\n",
    "\n",
    "\n",
    "def average_experiment_runs(runs_dfs: List[pd.DataFrame]) -> pd.DataFrame:\n",
    "    return pd.concat(runs_dfs).groupby(['trial', 'phase']).mean().reset_index(level='phase')\n",
    "\n",
    "\n",
    "def plot_cp(epsilon_greedy_df, action_delay_df, knowledge_array_df, op_initial_df, explore_trials, buckets):\n",
    "    fig = plt.figure(figsize=(14, 10))\n",
    "\n",
    "    # Plots layout\n",
    "    gs = fig.add_gridspec(2, 1, hspace=.4)\n",
    "    ax1 = fig.add_subplot(gs[0])\n",
    "    ax2 = fig.add_subplot(gs[1])\n",
    "\n",
    "    # Global title\n",
    "    fig.suptitle(f'Performance of CartPole environment discretized with {buckets} buckets', fontsize=24)\n",
    "\n",
    "    # Each axis\n",
    "    ma_window = 5  # moving average window\n",
    "\n",
    "    # Steps in trial\n",
    "    epsilon_greedy_df['steps_in_trial'].rolling(window=ma_window).mean().plot(label='Epsilon Greedy', c=COLORS['eg'],\n",
    "                                                                              ax=ax1)\n",
    "    action_delay_df['steps_in_trial'].rolling(window=ma_window).mean().plot(label='Action Delay', c=COLORS['ad'],\n",
    "                                                                            ax=ax1)\n",
    "    knowledge_array_df['steps_in_trial'].rolling(window=ma_window).mean().plot(label='Knowledge Array', c=COLORS['ka'],\n",
    "                                                                               ax=ax1)\n",
    "    op_initial_df['steps_in_trial'].rolling(window=ma_window).mean().plot(label='Optimistic Initial Quality',\n",
    "                                                                          c=COLORS['oiq'], ax=ax1)\n",
    "\n",
    "    ax1.axvline(x=explore_trials, color='red', linewidth=1, linestyle=\"--\")\n",
    "    ax1.axhline(y=195, color='black', linewidth=1, linestyle=\"--\")\n",
    "\n",
    "    ax1.set_xlabel('Trial')\n",
    "    ax1.set_ylabel('Steps')\n",
    "    ax1.set_title(f'Steps in each trial')\n",
    "    ax1.set_ylim(0, 200)\n",
    "\n",
    "    # Population\n",
    "    epsilon_greedy_df['reliable'].rolling(window=ma_window).mean().plot(label='Epsilon Greedy', c=COLORS['eg'], ax=ax2)\n",
    "    action_delay_df['reliable'].rolling(window=ma_window).mean().plot(label='Action Delay', c=COLORS['ad'], ax=ax2)\n",
    "    knowledge_array_df['reliable'].rolling(window=ma_window).mean().plot(label='Knowledge Array', c=COLORS['ka'],\n",
    "                                                                         ax=ax2)\n",
    "    op_initial_df['reliable'].rolling(window=ma_window).mean().plot(label='Optimistic Initial Quality', c=COLORS['oiq'],\n",
    "                                                                    ax=ax2)\n",
    "\n",
    "    ax2.axvline(x=explore_trials, color='red', linewidth=1, linestyle=\"--\")\n",
    "\n",
    "    ax2.set_xlabel('Trial')\n",
    "    ax2.set_ylabel('Classifiers')\n",
    "    ax2.set_title(f'Reliable classifiers')\n",
    "\n",
    "    # Create legend\n",
    "    handles, labels = ax2.get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='lower center', ncol=4)\n",
    "\n",
    "    # Save plot to file\n",
    "    fig.savefig(f'{plot_dir}/cartpole-performance.png', dpi=PLOT_DPI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Experiment 3 - Balacing the pole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "class CartPoleObservationWrapper(gym.ObservationWrapper):\n",
    "    # https://medium.com/@tuzzer/cart-pole-balancing-with-q-learning-b54c6068d947\n",
    "    # _high = [env.observation_space.high[0], 0.5, env.observation_space.high[2], math.radians(50)]\n",
    "    # _low = [env.observation_space.low[0], -0.5, env.observation_space.low[2], -math.radians(50)]\n",
    "    def __init__(self, env, buckets):\n",
    "        super().__init__(env)\n",
    "        self._high = [env.observation_space.high[0], 0.5, env.observation_space.high[2], 3500]\n",
    "        self._low = [env.observation_space.low[0], -0.5, env.observation_space.low[2], -3500]\n",
    "        self._buckets = buckets\n",
    "\n",
    "    def observation(self, obs):\n",
    "        ratios = [(obs[i] + abs(self._low[i])) / (self._high[i] - self._low[i]) for i in range(len(obs))]\n",
    "        new_obs = [int(round((self._buckets[i] - 1) * ratios[i])) for i in range(len(obs))]\n",
    "        new_obs = [min(self._buckets[i] - 1, max(0, new_obs[i])) for i in range(len(obs))]\n",
    "        return [str(o) for o in new_obs]\n",
    "\n",
    "\n",
    "def cp_env_provider(buckets: Tuple[int]):\n",
    "    return CartPoleObservationWrapper(gym.make('CartPole-v0'), buckets)\n",
    "\n",
    "\n",
    "def cp_metrics(agent, env):\n",
    "    pop = agent.population\n",
    "    metrics = {}\n",
    "    metrics.update(population_metrics(pop, env))\n",
    "    return metrics\n",
    "\n",
    "\n",
    "cp_base_params = {\n",
    "    \"classifier_length\": 4,\n",
    "    \"number_of_possible_actions\": 2,\n",
    "    \"epsilon\": 0.9,\n",
    "    \"beta\": 0.01,\n",
    "    \"gamma\": 0.995,\n",
    "    \"initial_q\": 0.5,\n",
    "    \"theta_exp\": 50,\n",
    "    \"theta_ga\": 50,\n",
    "    \"do_ga\": True,\n",
    "    \"chi\": 0.0,\n",
    "    \"mu\": 0.03,\n",
    "    \"metrics_trial_frequency\": 1,\n",
    "    \"user_metrics_collector_fcn\": cp_metrics\n",
    "}\n",
    "\n",
    "NUM_EXPERIMENTS = 50\n",
    "USE_RAY = True\n",
    "\n",
    "explore_trials, exploit_trials = 500, 500\n",
    "\n",
    "# Bucket configurations\n",
    "buckets_v1 = (1, 1, 6, 6)\n",
    "buckets_v2 = (4, 4, 4, 4)\n",
    "buckets_v3 = (2, 2, 6, 6)\n",
    "buckets_v4 = (1, 2, 4, 4)\n",
    "buckets_v5 = (1, 1, 8, 8)\n",
    "\n",
    "def buckets_to_str(buckets, delimiter = '_'):\n",
    "    return f'{delimiter.join(map(str, buckets))}'\n",
    "\n",
    "\n",
    "def run_cart_pole_biased_exploration(buckets):\n",
    "    env_provider = lambda: cp_env_provider(buckets)\n",
    "\n",
    "    eg = run_experiment(env_provider,\n",
    "                        explore_trials,\n",
    "                        exploit_trials,\n",
    "                        **(cp_base_params | {'action_selector': EpsilonGreedy}))\n",
    "\n",
    "    ad = run_experiment(env_provider,\n",
    "                        explore_trials,\n",
    "                        exploit_trials,\n",
    "                        **(cp_base_params | {'action_selector': ActionDelay, 'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    ka = run_experiment(env_provider,\n",
    "                        explore_trials,\n",
    "                        exploit_trials,\n",
    "                        **(cp_base_params | {'action_selector': KnowledgeArray, 'biased_exploration_prob': 0.5}))\n",
    "\n",
    "    oiq = run_experiment(env_provider,\n",
    "                         explore_trials,\n",
    "                         exploit_trials,\n",
    "                         **(cp_base_params | {'action_selector': EpsilonGreedy, 'biased_exploration_prob': 0.8}))\n",
    "\n",
    "    return eg, ad, ka, oiq\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/cart_pole/{buckets_to_str(buckets_v1)}.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def cp_buckets_v1():\n",
    "    return run_cart_pole_biased_exploration(buckets_v1)\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/cart_pole/{buckets_to_str(buckets_v2)}.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def cp_buckets_v2():\n",
    "    return run_cart_pole_biased_exploration(buckets_v2)\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/cart_pole/{buckets_to_str(buckets_v3)}.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def cp_buckets_v3():\n",
    "    return run_cart_pole_biased_exploration(buckets_v3)\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/cart_pole/{buckets_to_str(buckets_v4)}.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def cp_buckets_v4():\n",
    "    return run_cart_pole_biased_exploration(buckets_v4)\n",
    "\n",
    "\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/cart_pole/{buckets_to_str(buckets_v5)}.dill')\n",
    "@repeat(num_times=NUM_EXPERIMENTS, use_ray=USE_RAY)\n",
    "def cp_buckets_v5():\n",
    "    return run_cart_pole_biased_exploration(buckets_v5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "def extract(experiment_runs):\n",
    "    eg_dfs, ad_dfs, ka_dfs, oiq_dfs = [], [], [], []\n",
    "\n",
    "    for eg_df, ad_df, ka_df, oiq_df in experiment_runs:\n",
    "        eg_dfs.append(eg_df)\n",
    "        ad_dfs.append(ad_df)\n",
    "        ka_dfs.append(ka_df)\n",
    "        oiq_dfs.append(oiq_df)\n",
    "\n",
    "    return eg_dfs, ad_dfs, ka_dfs, oiq_dfs\n",
    "\n",
    "\n",
    "# Run the calculations\n",
    "cp_bv1_eg_dfs, cp_bv1_ad_dfs, cp_bv1_ka_dfs, cp_bv1_oiq_dfs = extract(cp_buckets_v1())\n",
    "cp_bv2_eg_dfs, cp_bv2_ad_dfs, cp_bv2_ka_dfs, cp_bv2_oiq_dfs = extract(cp_buckets_v2())\n",
    "cp_bv3_eg_dfs, cp_bv3_ad_dfs, cp_bv3_ka_dfs, cp_bv3_oiq_dfs = extract(cp_buckets_v3())\n",
    "cp_bv4_eg_dfs, cp_bv4_ad_dfs, cp_bv4_ka_dfs, cp_bv4_oiq_dfs = extract(cp_buckets_v4())\n",
    "cp_bv5_eg_dfs, cp_bv5_ad_dfs, cp_bv5_ka_dfs, cp_bv5_oiq_dfs = extract(cp_buckets_v5())\n",
    "\n",
    "# Plot visualization\n",
    "plot_cp(\n",
    "    average_experiment_runs(cp_bv1_eg_dfs),\n",
    "    average_experiment_runs(cp_bv1_ad_dfs),\n",
    "    average_experiment_runs(cp_bv1_ka_dfs),\n",
    "    average_experiment_runs(cp_bv1_oiq_dfs),\n",
    "    explore_trials=explore_trials,\n",
    "    buckets=buckets_v1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    ":::{figure-md} cp-fig\n",
    ":class: full-width\n",
    "<img src=\"../../_static/plots/4_biased_exploration/cartpole-performance.png\">\n",
    "\n",
    "Performance in CartPole environment\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Classifiers lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[##23 0 ####]\t\tmark: 00##\tquality: 0.96\treward: 3.34\tnumerosity: 1\n",
      "[##32 1 ####]\t\tmark: 00##\tquality: 0.96\treward: 3.24\tnumerosity: 1\n",
      "[##22 1 ####]\t\tmark: 00##\tquality: 0.98\treward: 2.78\tnumerosity: 1\n",
      "[##33 0 ####]\t\tmark: 00##\tquality: 0.95\treward: 2.23\tnumerosity: 3\n",
      "[##12 0 ####]\t\tmark: 00##\tquality: 0.98\treward: 1.44\tnumerosity: 1\n",
      "[##12 1 ####]\t\tmark: empty\tquality: 1.00\treward: 1.36\tnumerosity: 20\n",
      "[##43 1 ####]\t\tmark: 00##\tquality: 0.97\treward: 1.32\tnumerosity: 6\n",
      "[##43 0 ####]\t\tmark: empty\tquality: 1.00\treward: 1.22\tnumerosity: 20\n"
     ]
    }
   ],
   "source": [
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/cart_pole/epsilon_greedy_single_run.dill')\n",
    "def cp_single_run():\n",
    "    cfg = Configuration(**(cp_base_params | {'action_selector': EpsilonGreedy}))\n",
    "    agent = ACS2(cfg)\n",
    "    agent.explore(cp_env_provider(buckets_v1), explore_trials)\n",
    "    return agent  # only interested in resulting population\n",
    "\n",
    "\n",
    "# execute run\n",
    "cp_agent = cp_single_run()\n",
    "\n",
    "reliable = [cl for cl in cp_agent.population if cl.is_reliable()]\n",
    "for cl in sorted(reliable, key=lambda cl: -cl.fitness):\n",
    "    print(\n",
    "        f'[{cl.condition} {cl.action} {cl.effect}]\\t\\tmark: {cl.mark}\\tquality: {cl.q:.2f}\\treward: {cl.r:.2f}\\tnumerosity: {cl.num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Statistical verification\n",
    "\n",
    "```{admonition} Hypothesis testing\n",
    ":class: tip\n",
    "Here the best idea in my opinion would be to evaluate different discretization buckets combinations. But this requires a research and experiments on it own. Suggestion is to propose 4-5 reasonable configurations and distributions for the number of steps and classifiers count in each situation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/papermill.record/text/plain": "<IPython.core.display.HTML object>",
      "application/papermill.record/text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">       </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">1,1,6,6</td><td style=\"text-align: right;\">          178.40</td><td style=\"text-align: right;\">        138.69</td><td style=\"text-align: right;\">           175.72</td><td style=\"text-align: right;\">                      171.20</td></tr>\n<tr><td style=\"text-align: right;\">4,4,4,4</td><td style=\"text-align: right;\">           18.85</td><td style=\"text-align: right;\">         19.14</td><td style=\"text-align: right;\">            20.34</td><td style=\"text-align: right;\">                       18.56</td></tr>\n<tr><td style=\"text-align: right;\">2,2,6,6</td><td style=\"text-align: right;\">           59.73</td><td style=\"text-align: right;\">         44.58</td><td style=\"text-align: right;\">            95.68</td><td style=\"text-align: right;\">                       60.72</td></tr>\n<tr><td style=\"text-align: right;\">1,2,4,4</td><td style=\"text-align: right;\">          133.93</td><td style=\"text-align: right;\">        150.62</td><td style=\"text-align: right;\">           128.70</td><td style=\"text-align: right;\">                      132.36</td></tr>\n<tr><td style=\"text-align: right;\">1,1,8,8</td><td style=\"text-align: right;\">          181.61</td><td style=\"text-align: right;\">        154.09</td><td style=\"text-align: right;\">           172.75</td><td style=\"text-align: right;\">                      176.42</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {
      "scrapbook": {
       "name": "average_steps",
       "mime_prefix": "application/papermill.record/"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/papermill.record/text/plain": "<IPython.core.display.HTML object>",
      "application/papermill.record/text/html": "<table>\n<thead>\n<tr><th style=\"text-align: right;\">       </th><th style=\"text-align: right;\">  Epsilon Greedy</th><th style=\"text-align: right;\">  Action Delay</th><th style=\"text-align: right;\">  Knowledge Array</th><th style=\"text-align: right;\">  Optimistic Initial Quality</th></tr>\n</thead>\n<tbody>\n<tr><td style=\"text-align: right;\">1,1,6,6</td><td style=\"text-align: right;\">       8.0 ± 0.0</td><td style=\"text-align: right;\">   9.39 ± 0.18</td><td style=\"text-align: right;\">      9.01 ± 0.23</td><td style=\"text-align: right;\">                   8.0 ± 0.0</td></tr>\n<tr><td style=\"text-align: right;\">4,4,4,4</td><td style=\"text-align: right;\">     6.33 ± 0.26</td><td style=\"text-align: right;\">   4.38 ± 0.19</td><td style=\"text-align: right;\">      5.65 ± 0.23</td><td style=\"text-align: right;\">                 6.06 ± 0.23</td></tr>\n<tr><td style=\"text-align: right;\">2,2,6,6</td><td style=\"text-align: right;\">     6.99 ± 0.25</td><td style=\"text-align: right;\">   7.29 ± 0.25</td><td style=\"text-align: right;\">      8.27 ± 0.33</td><td style=\"text-align: right;\">                 7.48 ± 0.31</td></tr>\n<tr><td style=\"text-align: right;\">1,2,4,4</td><td style=\"text-align: right;\">    11.23 ± 0.18</td><td style=\"text-align: right;\">   9.83 ± 0.18</td><td style=\"text-align: right;\">     10.01 ± 0.18</td><td style=\"text-align: right;\">                10.86 ± 0.22</td></tr>\n<tr><td style=\"text-align: right;\">1,1,8,8</td><td style=\"text-align: right;\">     9.14 ± 0.12</td><td style=\"text-align: right;\">   8.92 ± 0.12</td><td style=\"text-align: right;\">     10.42 ± 0.21</td><td style=\"text-align: right;\">                 9.18 ± 0.14</td></tr>\n</tbody>\n</table>"
     },
     "metadata": {
      "scrapbook": {
       "name": "bayes_reliable_classifies",
       "mime_prefix": "application/papermill.record/"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiments_data = {\n",
    "    buckets_v1: [cp_bv1_eg_dfs, cp_bv1_ad_dfs, cp_bv1_ka_dfs, cp_bv1_oiq_dfs],\n",
    "    buckets_v2: [cp_bv2_eg_dfs, cp_bv2_ad_dfs, cp_bv2_ka_dfs, cp_bv2_oiq_dfs],\n",
    "    buckets_v3: [cp_bv3_eg_dfs, cp_bv3_ad_dfs, cp_bv3_ka_dfs, cp_bv3_oiq_dfs],\n",
    "    buckets_v4: [cp_bv4_eg_dfs, cp_bv4_ad_dfs, cp_bv4_ka_dfs, cp_bv4_oiq_dfs],\n",
    "    buckets_v5: [cp_bv5_eg_dfs, cp_bv5_ad_dfs, cp_bv5_ka_dfs, cp_bv5_oiq_dfs]\n",
    "}\n",
    "\n",
    "def train_bayes_model(dfs, query_condition, field):\n",
    "    data_arr = pd.concat(dfs).query(query_condition)[field].to_numpy()\n",
    "    bayes_model = bayes_estimate(data_arr)\n",
    "    return bayes_model['mu'], bayes_model['std']\n",
    "\n",
    "def build_models(dfs: Dict, field: str, query_condition: str):\n",
    "    results = {}\n",
    "\n",
    "    for bucket, dfs in dfs.items():\n",
    "        posteriors = [train_bayes_model(df, query_condition, field) for df in dfs]\n",
    "        results[bucket] = posteriors\n",
    "\n",
    "    return results\n",
    "\n",
    "def print_bayes_table(data):\n",
    "    table_data = [[buckets_to_str(bucket, ',')] + rewards for bucket, rewards in data.items()]\n",
    "\n",
    "    table = tabulate(table_data,\n",
    "                     headers=['', 'Epsilon Greedy', 'Action Delay', 'Knowledge Array', 'Optimistic Initial Quality'],\n",
    "                     tablefmt=\"html\", stralign='right', floatfmt=\".2f\")\n",
    "\n",
    "    return HTML(table)\n",
    "\n",
    "print_row = lambda r: f'{round(r[0].mean(), 2)} ± {round(r[0].std(), 2)}'\n",
    "\n",
    "# Average Steps in exploit phase\n",
    "avg_reward = lambda dfs: pd.concat(dfs).query('phase == \"exploit\"')['steps_in_trial'].mean()\n",
    "\n",
    "average_rewards_data = {}\n",
    "for bucket, dfs in experiments_data.items():\n",
    "    average_rewards_data[bucket] = list(map(avg_reward, dfs))\n",
    "\n",
    "# reliable classifiers\n",
    "@get_from_cache_or_run(cache_path=f'{cache_dir}/cart_pole/bayes/reliable.dill')\n",
    "def build_reliable_models(dfs: Dict):\n",
    "    return build_models(dfs, field='reliable', query_condition=f'trial == {explore_trials - 1}')\n",
    "\n",
    "# run computations\n",
    "reliable_data = build_reliable_models(experiments_data)\n",
    "\n",
    "reliable_table_data = {}\n",
    "for bucket, models in reliable_data.items():\n",
    "    reliable_table_data[bucket] = list(map(print_row, models))\n",
    "\n",
    "# Add glue objects\n",
    "glue('average_steps', print_bayes_table(average_rewards_data), display=False)\n",
    "glue('bayes_reliable_classifies', print_bayes_table(reliable_table_data), display=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "```{tabbed} Average Number of Steps\n",
    "{glue:}`average_steps`\n",
    "```\n",
    "\n",
    "```{tabbed} Reliable classifiers\n",
    "{glue:}`bayes_reliable_classifies`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Observations\n",
    "Why bucketing was chosen by hand (problem with hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "**Software packages used**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import session_info\n",
    "\n",
    "session_info.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}