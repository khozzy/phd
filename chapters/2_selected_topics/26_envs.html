
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>2.5. Overview of the selected environments &#8212; Real-valued Anticipatory Classifier System</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="3. Ways of handling real-valued input signal" href="../3_internalizing/31_introduction.html" />
    <link rel="prev" title="2.4. Statistical verification of results" href="25_stats.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/pwr_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Real-valued Anticipatory Classifier System</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Real-valued Anticipatory Classifier System
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../1_introduction/11_introduction.html">
   1. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_introduction/12_motivation.html">
     1.1. Motivation and challenges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_introduction/13_aims_goals.html">
     1.2. Research hypothesis, its aims and goals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_introduction/14_structure.html">
     1.3. Thesis structure
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="21_introduction.html">
   2. Selected topics of Learning Classifier Systems
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2">
    <a class="reference internal" href="22_alcs_history.html">
     2.1. Road towards Anticipatory Learning Classifier Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="23_real_value_challenge.html">
     2.2. Real-valued signal challenge
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="24_kpi.html">
     2.3. Key performance indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="25_stats.html">
     2.4. Statistical verification of results
    </a>
   </li>
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     2.5. Overview of the selected environments
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../3_internalizing/31_introduction.html">
   3. Ways of handling real-valued input signal
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../3_internalizing/interval/32_interval_based_representation.html">
     3.1. Interval-based representation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../3_internalizing/interval/32_experiment_1.html">
       Experiment 1 - Encoding precision
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../3_internalizing/interval/32_experiment_2.html">
       Experiment 2 - Nature of the intervals
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../3_internalizing/discretization/33_discretizing_input_signal.html">
     3.2. Discretizing input signal
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../3_internalizing/discretization/33_experiment_3.html">
       Experiment 3 - Single step
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../3_internalizing/discretization/33_experiment_4.html">
       Experiment 4 - Multistep environments
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../4_biased_exploration/41_introduction.html">
   4. Optimizing formation of internal model
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../4_biased_exploration/41_biased_exploration.html">
     4.1. Biased exploration
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../4_biased_exploration/41_experiment_1.html">
       Experiment 1 - Multi-steps problems performance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../4_biased_exploration/41_experiment_2.html">
       Experiment 2 - Single-step problem performance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../4_biased_exploration/41_experiment_3.html">
       Experiment 3 - Balacing the pole
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../5_diminishing_reward/51_introduction.html">
   5. Optimizing distributing reward through long action chains
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../5_diminishing_reward/51_diminishing_reward.html">
     5.1. Diminishing reward
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../5_diminishing_reward/51_experiment_1.html">
       Experiment 1 - Corridor environment
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../5_diminishing_reward/51_experiment_2.html">
       Experiment 2 - Finite-State-World environment
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../5_diminishing_reward/51_experiment_3.html">
       Experiment 3 - Woods1 environment
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../6_summary/61_summary.html">
   6. Summary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../abbreviations.html">
   7. Abbreviations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../bibliography.html">
   8. Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/chapters/2_selected_topics/26_envs.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/khozzy/phd"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/khozzy/phd/issues/new?title=Issue%20on%20page%20%2Fchapters/2_selected_topics/26_envs.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/khozzy/phd/gh-pages?urlpath=tree/chapters/2_selected_topics/26_envs.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#corridor">
   Corridor
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#grid">
   Grid
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#real-multiplexer">
   Real Multiplexer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checkerboard">
   Checkerboard
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cart-pole">
   Cart Pole
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finite-state-worlds-fsw">
   Finite State Worlds (FSW)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#woods1">
   Woods1
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Overview of the selected environments</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#corridor">
   Corridor
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#grid">
   Grid
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#real-multiplexer">
   Real Multiplexer
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#checkerboard">
   Checkerboard
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cart-pole">
   Cart Pole
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#finite-state-worlds-fsw">
   Finite State Worlds (FSW)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#woods1">
   Woods1
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pathlib</span>

<span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="kn">from</span> <span class="nn">myst_nb</span> <span class="kn">import</span> <span class="n">glue</span>
<span class="kn">from</span> <span class="nn">tabulate</span> <span class="kn">import</span> <span class="n">tabulate</span>

<span class="kn">from</span> <span class="nn">src.utils</span> <span class="kn">import</span> <span class="n">build_plots_dir_path</span>
<span class="kn">from</span> <span class="nn">src.visualization</span> <span class="kn">import</span> <span class="n">PLOT_DPI</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ioff</span><span class="p">()</span>  <span class="c1"># turn off interactive plotting</span>

<span class="n">root_dir</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">()</span><span class="o">.</span><span class="n">cwd</span><span class="p">()</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">parent</span><span class="o">.</span><span class="n">parent</span>
<span class="n">cwd_dir_name</span> <span class="o">=</span> <span class="n">pathlib</span><span class="o">.</span><span class="n">Path</span><span class="p">()</span><span class="o">.</span><span class="n">cwd</span><span class="p">()</span><span class="o">.</span><span class="n">name</span>

<span class="n">plot_dir</span> <span class="o">=</span> <span class="n">build_plots_dir_path</span><span class="p">(</span><span class="n">root_dir</span><span class="p">)</span> <span class="o">/</span> <span class="n">cwd_dir_name</span>
</pre></div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="overview-of-the-selected-environments">
<span id="section-topics-environments"></span><h1><span class="section-number">2.5. </span>Overview of the selected environments<a class="headerlink" href="#overview-of-the-selected-environments" title="Permalink to this headline">¶</a></h1>
<p>The range od problem domains to which ALCS can be divided is broadly divided into two categories: classification problems and reinforcement learning problems <span id="id1">[<a class="reference internal" href="../../bibliography.html#id10">85</a>]</span>. <em>Classification problems</em> seek to find a compact set of rules that classify all problem instances with maximal accuracy. They frequently rely on supervised learning where feedback is provided instantly. The <em>Reinforcement Learning</em> problems seek to find an optimal behavioral policy also represented by a compact set of rules. These problems are typically distinguished by inconsistent environmental reward, often requiring multiple actions before reward is obtained. They can be further discriminated by having Markov properties <span id="id2">[<a class="reference internal" href="../../bibliography.html#id45">35</a>]</span> <span id="id3">[<a class="reference internal" href="../../bibliography.html#id46">86</a>]</span> <span id="id4">[<a class="reference internal" href="../../bibliography.html#id47">87</a>]</span>.</p>
<p>This section describes six, both single- and multi-steps  environments used in further experiments. All of them are stationary, Markov toy-problems exhibiting real-valued properties facilitating the evaluation of modifications of anticipatory systems. Most of the environments were used as benchmarks in other works related to measuring the performance of the LCS, however the <a class="reference internal" href="#section-topics-environments-cartpole"><span class="std std-ref">Cart Pole</span></a> environment was never used in this class of algorithms before.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition-stationary-environment admonition">
<p class="admonition-title">Stationary environment</p>
<p>A stationary environment refers to data-generating distributions that <strong>do not change over time</strong>.</p>
</div>
</div>
<p>All the mentioned environments poses the standardized interface for enabling the agent to interact with it in consistent manner. In each step they present the current observation (that is not equal to its internal state), possible reward from previously executed action and the information whether the interaction is finished. In most cases there is a certain reward state, that acts as an incentive, motivating the forager to reach it.</p>
<div class="section" id="corridor">
<span id="section-topics-environments-corridor"></span><h2>Corridor<a class="headerlink" href="#corridor" title="Permalink to this headline">¶</a></h2>
<p>The corridor is a 1D multi-step, linear environment introduced by Lanzi to evaluate the XCSF agent <span id="id5">[<a class="reference internal" href="../../bibliography.html#id2">88</a>]</span>. The system output is defined over a finite discrete interval <span class="math notranslate nohighlight">\([0,n]\)</span>. On each trial, the agent is placed randomly on the path and can execute two possible actions - move left or right (which corresponds to moving one unit in a particular direction - see Figure <a class="reference internal" href="#corridor-env"><span class="std std-numref">2.11</span></a>.</p>
<div class="figure align-default" id="corridor-env">
<a class="reference internal image-reference" href="../../_images/corridor.png"><img alt="../../_images/corridor.png" src="../../_images/corridor.png" style="width: 75%;" /></a>
<p class="caption"><span class="caption-number">Fig. 2.11 </span><span class="caption-text">The <em>Corridor</em> environment. The size of the input space is <span class="math notranslate nohighlight">\(n\)</span>.</span><a class="headerlink" href="#corridor-env" title="Permalink to this image">¶</a></p>
</div>
<p>Lanzi used a real-valued version of this environment where the agent location is elucidated by a value between <span class="math notranslate nohighlight">\([0,1]\)</span>. Predefined step size was added to the current position when it executed an action, thus changing its value. When the agent reaches the final state <span class="math notranslate nohighlight">\(s = 1.0\)</span>, the reward is paid out.</p>
<p>The environment examined herein signifies the state already in discretized form, available in three preconfigured sizes with increasing difficulty. The main challenge for the agent here is mainly to successfully learn the reward distribution in possibly long action chains.</p>
<p><strong>Reward scheme</strong>: The trial ends when it reaches the final state <span class="math notranslate nohighlight">\(n\)</span> (obtaining reward <span class="math notranslate nohighlight">\(r=1000\)</span>) or when the maximum number of 200 steps in each episode is exceeded. Otherwise, the reward after each step is <span class="math notranslate nohighlight">\(r=0\)</span>.</p>
</div>
<div class="section" id="grid">
<span id="section-topics-environments-grid"></span><h2>Grid<a class="headerlink" href="#grid" title="Permalink to this headline">¶</a></h2>
<p>Grid refers to an extension of the <a class="reference internal" href="#section-topics-environments-corridor"><span class="std std-ref">Corridor</span></a> environment <span id="id6">[<a class="reference internal" href="../../bibliography.html#id2">88</a>]</span>. A vertical dimension and two new actions (move up, move down) are added. The raw agent perception is now identified as a pair of real numbers <span class="math notranslate nohighlight">\((s_0, s_1)\)</span>, where <span class="math notranslate nohighlight">\(s \in [0,1]\)</span>. Similarly, the environment is presented to the agent in a discretized form. Each dimension is divided into <span class="math notranslate nohighlight">\(n-1\)</span> equally spaced buckets - see Figure <a class="reference internal" href="#grid-env"><span class="std std-numref">2.12</span></a>.</p>
<div class="figure align-default" id="grid-env">
<a class="reference internal image-reference" href="../../_images/grid.png"><img alt="../../_images/grid.png" src="../../_images/grid.png" style="width: 75%;" /></a>
<p class="caption"><span class="caption-number">Fig. 2.12 </span><span class="caption-text">The <em>Grid</em> environment. The size of the input space is <span class="math notranslate nohighlight">\(n^2\)</span>. The agent can change its position by moving in four different directions.</span><a class="headerlink" href="#grid-env" title="Permalink to this image">¶</a></p>
</div>
<p><strong>Reward scheme</strong>: The trial ends with reward <span class="math notranslate nohighlight">\(r=1000\)</span> when the final state <span class="math notranslate nohighlight">\((n, n)\)</span> is reached. Otherwise, the reward after each step is <span class="math notranslate nohighlight">\(r=0\)</span>. Additionally, the episode is terminated after exceeding the maximum number of 2000 steps.</p>
</div>
<div class="section" id="real-multiplexer">
<span id="section-topics-environments-rmpx"></span><h2>Real Multiplexer<a class="headerlink" href="#real-multiplexer" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">gym_multiplexer</span>  <span class="c1"># noqa: F401</span>

<span class="n">rmpx6bit_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;real-multiplexer-6bit-v0&#39;</span><span class="p">)</span>
<span class="n">random_state</span> <span class="o">=</span> <span class="n">rmpx6bit_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="n">threshold</span> <span class="o">=</span> <span class="mf">0.5</span>  <span class="c1"># secret knowledge</span>

<span class="n">t</span> <span class="o">=</span> <span class="n">HTML</span><span class="p">(</span><span class="n">tabulate</span><span class="p">([</span>
    <span class="p">[</span><span class="s1">&#39;&lt;b&gt;rMPX signal&lt;/b&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">round</span><span class="p">(</span><span class="n">s</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">random_state</span><span class="p">],</span>
    <span class="p">[</span><span class="s1">&#39;&lt;b&gt;MPX signal &lt;/b&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">threshold</span> <span class="k">else</span> <span class="mi">0</span><span class="p">,</span> <span class="n">random_state</span><span class="p">))</span>
<span class="p">],</span> <span class="n">tablefmt</span><span class="o">=</span><span class="s1">&#39;unsafehtml&#39;</span><span class="p">,</span> <span class="n">stralign</span><span class="o">=</span><span class="s1">&#39;right&#39;</span><span class="p">))</span>

<span class="n">glue</span><span class="p">(</span><span class="s1">&#39;rmpx_mpx_mapping_table&#39;</span><span class="p">,</span> <span class="n">t</span><span class="p">,</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>Wilson <span id="id7">[<a class="reference internal" href="../../bibliography.html#id3">18</a>]</span> introduced the modification to the traditional Boolean Multiplexer (MPX), called Real Multiplexer (rMPX) to examine the performance in single-step environments using real-valued data.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<div class="admonition-epistasis-and-heterogeneity admonition">
<p class="admonition-title">Epistasis and heterogeneity</p>
<p><strong>Epistasis</strong> describes an non-linear interaction effect between multiple features.</p>
<p><strong>Heterogenity</strong> means that for different sets of instances, a distinct subset of features will determine the class value.</p>
</div>
</div>
<p>The Boolean <em>n</em>-bit multiplexer defines a set of single-step supervised learning problems that are conceptually based on an electronic device taking multiple inputs and switching them to the single output. In each trial a random, fixed binary string of predefined length is generated. It comprises two parts - the address and register segments. The first one points to specific register address that is considered to be a truth value - Figure <a class="reference internal" href="#mpx6bit"><span class="std std-numref">2.13</span></a> describes the process. This environment is also particularly interesting because it possesses the properties of <em>epistasis</em>  and <em>heterogeneity</em>, which are often present in within real-world problems such as bioinformatics, finance or behaviour modelling.</p>
<div class="figure align-default" id="mpx6bit">
<a class="reference internal image-reference" href="../../_images/mpx6bit.png"><img alt="../../_images/mpx6bit.png" src="../../_images/mpx6bit.png" style="width: 75%;" /></a>
<p class="caption"><span class="caption-number">Fig. 2.13 </span><span class="caption-text">Visualization of determining the output value of 6 bit multiplexer. The address bit points to the first value of the register array that is considered the true output. Diagram taken from <span id="id8">[<a class="reference internal" href="../../bibliography.html#id8">89</a>]</span>.</span><a class="headerlink" href="#mpx6bit" title="Permalink to this image">¶</a></p>
</div>
<p>For the rMPX the only difference between boolean multiplexer is that generated perception consists of real-values drawn from a uniform distribution. To validate the correct answer, the additional variable - secret threshold <span class="math notranslate nohighlight">\(\theta = 0.5\)</span> is used to map each allele into binary form. See Table <a class="reference internal" href="#rmpx-mpx-mapping-table"><span class="std std-numref">2.14</span></a> for the example of such mapping.</p>
<div class="figure align-center" id="rmpx-mpx-mapping-table" style="width: 500px">
<div class="cell_output docutils container">
<div class="output text_html"><table>
<tbody>
<tr><td style="text-align: right;"><b>rMPX signal</b></td><td style="text-align: right;">0.94</td><td style="text-align: right;">0.07</td><td style="text-align: right;">0.15</td><td style="text-align: right;">0.11</td><td style="text-align: right;">0.33</td><td style="text-align: right;">0.77</td><td style="text-align: right;">0</td></tr>
<tr><td style="text-align: right;"><b>MPX signal </b></td><td style="text-align: right;">1   </td><td style="text-align: right;">0   </td><td style="text-align: right;">0   </td><td style="text-align: right;">0   </td><td style="text-align: right;">0   </td><td style="text-align: right;">1   </td><td style="text-align: right;">0</td></tr>
</tbody>
</table></div></div>
<p class="caption"><span class="caption-number">Fig. 2.14 </span><span class="caption-text">Example of mapping a random 6-bit rMPX signal into MPX problem. A threshold of <span class="math notranslate nohighlight">\(\theta=0.5\)</span> was used. The last bit is set to <span class="math notranslate nohighlight">\(0\)</span> as an initial value that will be changed to <span class="math notranslate nohighlight">\(1\)</span> after performing the correct action.</span><a class="headerlink" href="#rmpx-mpx-mapping-table" title="Permalink to this image">¶</a></p>
</div>
<p>The standard version, however, is still not suitable to be used with ALCS. Because an agent utilizes perceptual causality to form new classifiers, assuming that after executing an action, the state will change. The MPX does not have any possibility to send feedback about the correctness of the action. Butz suggested two solutions to this problem <span id="id9">[<a class="reference internal" href="../../bibliography.html#id6">64</a>]</span>. In this work, the assumption is that the state generated by the rMPX is extended by one extra bit, denoting whether the classification was successful. This bit is by default set to zero the agent responds correctly after being switched, thus providing a direct feedback. A detailed example can be found in <span id="id10">[<a class="reference internal" href="../../bibliography.html#id7">90</a>]</span>.</p>
<p><strong>Reward scheme</strong>: If the correct answer is given the reward <span class="math notranslate nohighlight">\(r=1000\)</span> is paid out, otherwise <span class="math notranslate nohighlight">\(r=0\)</span>.</p>
</div>
<div class="section" id="checkerboard">
<span id="section-topics-environments-checkerboard"></span><h2>Checkerboard<a class="headerlink" href="#checkerboard" title="Permalink to this headline">¶</a></h2>
<div class="cell tag_hide-input docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_checkerboard</span><span class="p">(</span><span class="n">plot_filename</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">gym_checkerboard</span>  <span class="c1"># noqa: F401</span>
    <span class="n">checkerboard_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">&#39;checkerboard-2D-3div-v0&#39;</span><span class="p">)</span>
    <span class="n">checkerboard_env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">np_board</span> <span class="o">=</span> <span class="n">checkerboard_env</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">_board</span><span class="o">.</span><span class="n">board</span>

    <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>

    <span class="n">ax</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">np_board</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">get_cmap</span><span class="p">(</span><span class="s1">&#39;gray_r&#39;</span><span class="p">),</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">plot_filename</span><span class="p">:</span>
        <span class="n">fig</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">plot_filename</span><span class="p">,</span> <span class="n">dpi</span><span class="o">=</span><span class="n">PLOT_DPI</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">fig</span>

<span class="n">glue</span><span class="p">(</span><span class="s1">&#39;checkerboard-env&#39;</span><span class="p">,</span> <span class="n">plot_checkerboard</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">plot_dir</span><span class="si">}</span><span class="s1">/checkerboard-env-visualization.png&#39;</span><span class="p">),</span> <span class="n">display</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>The Checkerboard is a single-step environment introduced by Stone in <span id="id11">[<a class="reference internal" href="../../bibliography.html#id11">20</a>]</span>. It was proposed to circumvent certain limitations of the <a class="reference internal" href="#section-topics-environments-rmpx"><span class="std std-ref">Real Multiplexer</span></a> when using the interval predicates approach. Because the rMPX problem can be solved by using just a hyperplane decision surface, it’s not considered of being able to represent arbitrary intervals in solution space. In order to solve the Checkerboard problem a hyper-rectangle decision surface is needed for modelling certain interval regions.</p>
<p>This environment works by dividing up the <span class="math notranslate nohighlight">\(n\)</span>-dimensional solution space into equal-sized hypercubes. Each hypercube is assigned a white or black color (alternating in all dimensions), see Figure <a class="reference internal" href="#checkerboard-env"><span class="std std-numref">2.15</span></a>. The problem difficulty can be controlled by changing both the dimensionality <span class="math notranslate nohighlight">\(n\)</span> and the number of divisions in each dimension <span class="math notranslate nohighlight">\(n_d\)</span>. In order to allow the colors to be alternating <span class="math notranslate nohighlight">\(n_d\)</span> must be an odd number.</p>
<div class="figure align-default" id="checkerboard-env">
<div class="cell_output docutils container">
<img alt="../../_images/26_envs_8_0.png" src="../../_images/26_envs_8_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 2.15 </span><span class="caption-text">2-dimensional Checkerboard problem with <span class="math notranslate nohighlight">\(n_d=3\)</span>. Precise interval predicates are needed for representing selected regions.</span><a class="headerlink" href="#checkerboard-env" title="Permalink to this image">¶</a></p>
</div>
<p>In each trial the environment presents a vector of length <span class="math notranslate nohighlight">\(n_d\)</span> or real numbers in the interval <span class="math notranslate nohighlight">\([0, 1)\)</span>, representing a point in the solution space. The agent’s goal is to guess the correct color by performing one of two actions depending on the colour (black or white) of a pointed hypercube.</p>
<p><strong>Reward scheme</strong>: When the correct answer is given the reward <span class="math notranslate nohighlight">\(r=1\)</span> is paid out, otherwise <span class="math notranslate nohighlight">\(r=0\)</span>.</p>
</div>
<div class="section" id="cart-pole">
<span id="section-topics-environments-cartpole"></span><h2>Cart Pole<a class="headerlink" href="#cart-pole" title="Permalink to this headline">¶</a></h2>
<p>Barto introduced the <a class="reference external" href="https://gym.openai.com/envs/CartPole-v0">Cart Pole</a> environment as a reinforcement learning control problem <span id="id12">[<a class="reference internal" href="../../bibliography.html#id17">91</a>]</span>. The task is to balance a pole that is hinged to a movable cart by applying forces (move left or move right) to the cart’s base (Figure <a class="reference internal" href="#cartpole-env"><span class="std std-numref">2.16</span></a>). The system starts upright, and its goal is to prevent the stick from falling over.</p>
<div class="figure align-default" id="cartpole-env">
<img alt="../../_images/cartpole.gif" src="../../_images/cartpole.gif" />
<p class="caption"><span class="caption-number">Fig. 2.16 </span><span class="caption-text">The Cart Pole environment. The goal is to maintain the pole upright for maximum number of trials.</span><a class="headerlink" href="#cartpole-env" title="Permalink to this image">¶</a></p>
</div>
<p>The observation returned by the environment is a vector of four elements - presented in <a class="reference internal" href="#cart-pole-observation-space-table"><span class="std std-numref">Table 2.1</span></a>. The challenge for the agent is that each attribute has specific range of possible values, and two of them additionally span the whole search space.</p>
<table class="table" id="cart-pole-observation-space-table">
<caption><span class="caption-number">Table 2.1 </span><span class="caption-text">Agent’s observation of the Cart Pole environment</span><a class="headerlink" href="#cart-pole-observation-space-table" title="Permalink to this table">¶</a></caption>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Num</p></th>
<th class="head"><p>Observation</p></th>
<th class="head"><p>Min</p></th>
<th class="head"><p>Max</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\sigma_0\)</span></p></td>
<td><p>Cart Position</p></td>
<td><p>-2.4</p></td>
<td><p>2.4</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\sigma_1\)</span></p></td>
<td><p>Cart Velocity</p></td>
<td><p><span class="math notranslate nohighlight">\(-\infty\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\infty\)</span></p></td>
</tr>
<tr class="row-even"><td><p><span class="math notranslate nohighlight">\(\sigma_2\)</span></p></td>
<td><p>Pole Angle</p></td>
<td><p><span class="math notranslate nohighlight">\(\sim\)</span>-41.8°</p></td>
<td><p><span class="math notranslate nohighlight">\(\sim\)</span>41.8°</p></td>
</tr>
<tr class="row-odd"><td><p><span class="math notranslate nohighlight">\(\sigma_3\)</span></p></td>
<td><p>Pole Velocity at Tip</p></td>
<td><p><span class="math notranslate nohighlight">\(-\infty\)</span></p></td>
<td><p><span class="math notranslate nohighlight">\(\infty\)</span></p></td>
</tr>
</tbody>
</table>
<p>The environment is considered as solved if the average reward if greater than or equal to 195 over last 100 trials.</p>
<p><strong>Reward scheme</strong>: After each step, a reward of +1 is provided. The episode ends when the pole is more than 15 degrees from vertical, or the cart moves more than 2.4 units from the center.</p>
</div>
<div class="section" id="finite-state-worlds-fsw">
<span id="section-topics-environments-fsw"></span><h2>Finite State Worlds (FSW)<a class="headerlink" href="#finite-state-worlds-fsw" title="Permalink to this headline">¶</a></h2>
<p>Barry <span id="id13">[<a class="reference internal" href="../../bibliography.html#id20">92</a>]</span> introduced the <em>Finite State World</em> (FSW) environment to investigate the limits of XCS performance in long multi-steps environments with a delayed reward. It consists of <em>nodes</em> and directed <em>edges</em> joining the nodes. Each node represents a distinct environmental state and is labeled with a unique state identifier. Each edge represents a possible transition path from one node to another and is also labeled with the action(s) that will cause the movement. An edge can also lead back to the same node. The graph layout used in the experiments is presented in Figure <a class="reference internal" href="#fsw-env"><span class="std std-numref">2.17</span></a>.</p>
<div class="figure align-default" id="fsw-env">
<img alt="../../_images/fsw.png" src="../../_images/fsw.png" />
<p class="caption"><span class="caption-number">Fig. 2.17 </span><span class="caption-text">A Finite State World of length 5 (FSW-5). Environment is especially suited for measuring a reward propagation for long action chains. Each trial always starts in state <span class="math notranslate nohighlight">\(s_0\)</span>, and the agent’s goal is to reach the final state <span class="math notranslate nohighlight">\(s_r\)</span>.</span><a class="headerlink" href="#fsw-env" title="Permalink to this image">¶</a></p>
</div>
<p>Although, the environment does not expose any real-valued state it can be treated as a further extension of a discretized <a class="reference internal" href="#section-topics-environments-corridor"><span class="std std-ref">Corridor</span></a>. Most importantly, the challenge is that the agent is presented with the sub-optimal route at every step, that slows for the pursuit of the reward. Additionally, the environment is easily scalable - changing the number of nodes, will change the total action chain length</p>
<p><strong>Reward scheme</strong>: A of reward <span class="math notranslate nohighlight">\(r = 100\)</span> is provided when agent reaches final state <span class="math notranslate nohighlight">\(s_r\)</span>, otherwise <span class="math notranslate nohighlight">\(r=0\)</span>.</p>
</div>
<div class="section" id="woods1">
<span id="section-topics-environments-woods1"></span><h2>Woods1<a class="headerlink" href="#woods1" title="Permalink to this headline">¶</a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Still not sure if this environment will be included in the work.</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/2_selected_topics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="25_stats.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">2.4. </span>Statistical verification of results</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../3_internalizing/31_introduction.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span class="section-number">3. </span>Ways of handling real-valued input signal</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Norbert Kozłowski<br/>
    
        &copy; Copyright 2021.<br/>
      <div class="extra_footer">
        <div><a href="https://wit.pwr.edu.pl/en/">Faculty of Computer Science and Telecommunications</a> - <a href="https://dce.pwr.edu.pl/">Department of Computer Engineering</a></div> 

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>