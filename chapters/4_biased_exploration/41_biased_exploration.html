
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4.1. Biased exploration &#8212; Real-valued Anticipatory Classifier System</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Experiment 1 - Single-step problem performance" href="41_experiment_1.html" />
    <link rel="prev" title="4. Optimizing formation of internal model" href="41_introduction.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/pwr_logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Real-valued Anticipatory Classifier System</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Real-valued Anticipatory Classifier System
  </a>
 </li>
</ul>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../1_introduction/11_introduction.html">
   1. Introduction
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_introduction/12_motivation.html">
     1.1. Motivation and challenges
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_introduction/13_aims_goals.html">
     1.2. Research hypothesis, its aims and goals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../1_introduction/14_structure.html">
     1.3. Thesis structure
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../2_selected_topics/21_introduction.html">
   2. Selected topics of Learning Classifier Systems
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_selected_topics/22_alcs_history.html">
     2.1. Road towards Anticipatory Learning Classifier Systems
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_selected_topics/23_real_value_challenge.html">
     2.2. Real-valued signal challenge
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_selected_topics/24_kpi.html">
     2.3. Key performance indicators
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_selected_topics/25_stats.html">
     2.4. Statistical verification of results
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../2_selected_topics/26_envs.html">
     2.5. Overview of the selected environments
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../3_internalizing/31_introduction.html">
   3. Ways of handling real-valued input signal
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../3_internalizing/interval/32_interval_based_representation.html">
     3.1. Interval-based representation
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../3_internalizing/interval/32_experiment_1.html">
       Experiment 1 - Encoding precision
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../3_internalizing/interval/32_experiment_2.html">
       Experiment 2 - Nature of the intervals
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../3_internalizing/discretization/33_discretizing_input_signal.html">
     3.2. Discretizing input signal
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../3_internalizing/discretization/33_experiment_3.html">
       Experiment 3 - Single-step environment performance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../3_internalizing/discretization/33_experiment_4.html">
       Experiment 4 - Multiple-step environments performance
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="41_introduction.html">
   4. Optimizing formation of internal model
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="current reference internal" href="#">
     4.1. Biased exploration
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
    <label for="toctree-checkbox-7">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="41_experiment_1.html">
       Experiment 1 - Single-step problem performance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="41_experiment_2.html">
       Experiment 2 - Multi-steps problems performance
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="41_experiment_3.html">
       Experiment 3 - Balancing the pole
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../5_diminishing_reward/51_introduction.html">
   5. Optimizing distributing reward through long action chains
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../5_diminishing_reward/51_diminishing_reward.html">
     5.1. Diminishing reward
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
    <label for="toctree-checkbox-9">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../5_diminishing_reward/51_experiment_1.html">
       Experiment 1 - Straight Corridor
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../5_diminishing_reward/51_experiment_2.html">
       Experiment 2 - Deceptive Corridor
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../6_summary/61_summary.html">
   6. Summary
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_summary/62_conclusions.html">
     6.1. Conclusions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_summary/63_future.html">
     6.2. Future Works
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../6_summary/64_publications.html">
     6.3. Publications
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../abbreviations.html">
   7. Abbreviations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../bibliography.html">
   8. Bibliography
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/chapters/4_biased_exploration/41_biased_exploration.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/khozzy/phd"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/khozzy/phd/issues/new?title=Issue%20on%20page%20%2Fchapters/4_biased_exploration/41_biased_exploration.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experimental-evaluation">
   Experimental evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#research-questions">
     Research questions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#goals-of-the-experiments">
     Goals of the experiments
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#experiments">
     Experiments
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#answers-to-research-questions">
     Answers to research questions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#q1-does-the-biased-exploration-methods-ad-ka-oiq-have-significantly-accelerate-the-agent-s-learning-speed">
       Q1: Does the biased exploration methods (AD, KA, OIQ) have significantly accelerate the agent’s learning speed?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#q2-can-the-oiq-method-improve-the-performance-in-terms-of-ingesting-knowledge-or-reducing-classifier-population-size">
       Q2: Can the OIQ method improve the performance in terms of ingesting knowledge or reducing classifier population size?
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Biased exploration</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#experimental-evaluation">
   Experimental evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#research-questions">
     Research questions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#goals-of-the-experiments">
     Goals of the experiments
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#experiments">
     Experiments
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#answers-to-research-questions">
     Answers to research questions
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#q1-does-the-biased-exploration-methods-ad-ka-oiq-have-significantly-accelerate-the-agent-s-learning-speed">
       Q1: Does the biased exploration methods (AD, KA, OIQ) have significantly accelerate the agent’s learning speed?
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#q2-can-the-oiq-method-improve-the-performance-in-terms-of-ingesting-knowledge-or-reducing-classifier-population-size">
       Q2: Can the OIQ method improve the performance in terms of ingesting knowledge or reducing classifier population size?
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="biased-exploration">
<h1><span class="section-number">4.1. </span>Biased exploration<a class="headerlink" href="#biased-exploration" title="Permalink to this headline">¶</a></h1>
<p>LCS are being considered as self-adaptive and autonomous learners. However, in order to reach full autonomy, the credit assignment part must decide on their own when to exploit the existing knowledge by taking the most promising action and when to deliberately select an action that is not apparent best to gain additional knowledge potentially.</p>
<p>This decision is commonly referred to as the explore/exploit (E/E) dilemma, since obtaining new knowledge through exploration incurs a short-term performance loss, while too much exploitation risks staying on an unnecessarily low level of performance in the long term <span id="id1">[<a class="reference internal" href="../../bibliography.html#id29">39</a>]</span>. In a typical exploration phase, the action is selected randomly with the intention of an unbiased exploration.</p>
<p>Such exploration might be inefficient for real-valued environments where the search space is presumably large. Certain regions of space might be explored multiple times, while the other ones remain unknown. Therefore, an approach towards optimizing the process of acquiring knowledge by suggesting more valuable actions is considered herein.</p>
<p>At first, model learning capabilities in ALCS was enhanced by Stolzmann and Butz by using behavioural capabilities (internal reinforcement learning or lookahead action selection) in <span id="id2">[<a class="reference internal" href="../../bibliography.html#id98">99</a>]</span> and by introducing the <em>action planning</em> mechanism <span id="id3">[<a class="reference internal" href="../../bibliography.html#id99">100</a>]</span> <span id="id4">[<a class="reference internal" href="../../bibliography.html#id100">67</a>]</span>.</p>
<p>Later, Butz suggested that by using computationally inexpensive methods by biasing exploration towards specially chosen regions of search-space, the model can be learned locally <span id="id5">[<a class="reference internal" href="../../bibliography.html#id101">101</a>]</span>.</p>
<p>This chapter aims to narrow the existing gap in research by experimentally comparing four biased exploration strategies. Any ALCS agent operating a large realm of observation space might take advantage of the possibility of improving the time needed to form an internal model. First, a baseline method - <em>epsilon-greedy</em>, which is a default option for LCS, will be described. Later two methods were introduced by Butz - <em>action-delay</em> and <em>knowledge-array</em> bias. They examine the match set <span class="math notranslate nohighlight">\([M]\)</span> searching for indications of which action might result in the highest information gain. Eventually, the latter approach is inspired by an “<em>Optimistic Initial Values</em>” approach described by Sutton in <span id="id6">[<a class="reference internal" href="../../bibliography.html#id29">39</a>]</span>. This strategy turned out to be very effective for Multi-armed bandit problems, where the main objective is to select the most promising action and was never examined in any LCS domain.
In most experiments, the rACS agent builds the population consisting primarily of Region 1 interval predicates. The amount of attributes represented as Region 3 and 4, spanning to the maximum value from the right side, tends to diminish. However, the results are correlated with the number of trials that were kept the same in all cases. More precise boundary representation naturally would require more trials to converge. However, for the first 4 bits, there is the following trend can be noticed when intensifying encoding resolution:</p>
<ul class="simple">
<li><p>Ratio of Region 1 attributes increases</p></li>
<li><p>Ratio of Region 2, 3, 4 attributes decreases</p></li>
</ul>
<p>This is caused by the lack of online rule compaction or consolidation mechanism. The only possibility for the agent to create a more general attribute is due to the mutation algorithm controlled by the <span class="math notranslate nohighlight">\(\epsilon_{mutation}\)</span> parameter. However, this value must be set carefully because limitations of selected encoding resolution can inadvertently ignore its effect.</p>
<p>The other metrics also show the hypothesis about the need for more trials. The size of the overall population is correlated with the number of encoding bits, but it became more difficult for the agent to discriminate between reliable classifiers. For example, when using 5-bits encoding after <span class="pasted-inline"><code class="output text_plain docutils literal notranslate"><span class="pre">15000</span></code></span> trials, there is no single reliable classifier despite having a population with more than 10 thousand individuals.</p>
<p>The experiment with 1-bit encoding also confirms the situation when it is impossible to learn the environment with hyper-plane decision boundary successfully. Such representation cannot handle regularities, resulting in unreliable classifiers and random average rewards from exploit runs.</p>
<div class="tip admonition">
<p class="admonition-title">Epsilon-Greedy (EG)</p>
<p>In the epsilon-greedy approach, the agent equally discovers all regions from the input-space, not favouring any specific behaviour. In each step, random action is executed with <span class="math notranslate nohighlight">\(p_{explr}\)</span> probability. Then it is chosen uniform randomly from classifiers composing a match set <span class="math notranslate nohighlight">\([M]\)</span>. In the case of <span class="math notranslate nohighlight">\(1-p_{explr}\)</span>, action from the most fitted classifier is executed. By doing so, the agent can occasionally perform the move he thinks is the best at a given time, reinforcing its beliefs about the consequences.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Action-Delay (AD)</p>
<p>This bias is based on the <em>recency-based</em> principle assuming that the action executed a long time ago might introduce new situation-action-effect triples. To determine which action was executed most long ago at the current time <span class="math notranslate nohighlight">\(t\)</span> the <span class="math notranslate nohighlight">\(t_{alp}\)</span> field of all classifiers in a match set <span class="math notranslate nohighlight">\([M](t)\)</span> is analyzed. For situation <span class="math notranslate nohighlight">\(\sigma(t)\)</span> the action of classifier <span class="math notranslate nohighlight">\(cl\)</span> with the lowest value of <span class="math notranslate nohighlight">\(t_{alp}\)</span> is selected.</p>
<p>In case there exists an action not represented by any classifier in <span class="math notranslate nohighlight">\([M](t)\)</span> that it is assumed to be experienced most long ago (if ever) and therefore chosen for execution.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Knowledge Array (KA)</p>
<p>This method, on the contrary, is based on the <em>error-based</em> principle. For ACS2, a quality <span class="math notranslate nohighlight">\(q\)</span> denoting the accuracy of predictions for each classifier can be used to measure it.</p>
<p>The bias generates the knowledge array KA from classifiers in a match set <span class="math notranslate nohighlight">\([M]\)</span> in which each entry specifies the averaged quality for the anticipation for each possible action - see Equation <a class="reference internal" href="#equation-ka-eq">(4.1)</a>.</p>
<div class="math notranslate nohighlight" id="equation-ka-eq">
<span class="eqno">(4.1)<a class="headerlink" href="#equation-ka-eq" title="Permalink to this equation">¶</a></span>\[KA[a] = \frac{\sum_{cl \in [M] \wedge cl.A = a}cl.q \cdot cl.num}{\sum_{cl \in [M] \wedge cl.A = a} cl.num}\]</div>
<p>An action with the lowest value in the knowledge array is selected for execution. Similarly, as in the action delay bias, if any classifiers do not express actions, they are chosen first.</p>
</div>
<div class="tip admonition">
<p class="admonition-title">Optimistic Initial Quality (OIQ)</p>
<p>By default, newly created classifiers <span class="math notranslate nohighlight">\(cl\)</span> have the initial quality set to <span class="math notranslate nohighlight">\(cl.q = 0.5\)</span>. It can be said that they are biased towards their initial quality. In practice, it should not be a problem because this value will converge to optimal ones over a set of trials. Changing this parameter provides an easy way of supplying the agent with the confidence of the generated classifiers.</p>
<p>In this method, the agent’s behaviour was parametrized by an extra parameter - <em>initial quality</em> - <span class="math notranslate nohighlight">\(q_0\)</span>. Every time a new classifier is generated, its quality is set to new value <span class="math notranslate nohighlight">\(cl.q = q_0\)</span>.</p>
<p>In all the experiments, there was fixed <span class="math notranslate nohighlight">\(q_0 = 0.8\)</span>, expecting the agent to build an internal model of knowledge representation faster (especially in the early stages). For the action selection strategy, the default epsilon-greedy method was chosen.</p>
</div>
<p>Interestingly, Hansmeier and Platzner made an effort to compare four strategies optimizing the time for alternating E/E  phases using the XCS algorithm <span id="id7">[<a class="reference internal" href="../../bibliography.html#id30">102</a>]</span>. It turned out that despite automized parameter tuning that none of the strategies is superior to the other. On the other side, they noticed that specific multi-step environments with scarce reward signals become challenging due to setting the classifier’s accuracy value too aggressively. Such problem with scarce reward and long action-chains is further discussed in the following chapter.</p>
<div class="section" id="experimental-evaluation">
<h2>Experimental evaluation<a class="headerlink" href="#experimental-evaluation" title="Permalink to this headline">¶</a></h2>
<p>This section presents the motivation, goals and setup of the performed experiments and their results.</p>
<div class="section" id="research-questions">
<h3>Research questions<a class="headerlink" href="#research-questions" title="Permalink to this headline">¶</a></h3>
<p>The conducted research aims to answer the following question regarding the rACS algorithm and the interval-based representation</p>
<ol class="simple">
<li><p>Does the biased exploration methods (AD, KA, OIQ) significantly accelerate the agent’s learning speed?</p></li>
<li><p>Can the OIQ method improve the performance of ingesting knowledge or reducing classifier population size?</p></li>
</ol>
</div>
<div class="section" id="goals-of-the-experiments">
<h3>Goals of the experiments<a class="headerlink" href="#goals-of-the-experiments" title="Permalink to this headline">¶</a></h3>
<p>The difference between the four exploration methods will be compared using the ACS2 agent in all the experiments.</p>
<div class="admonition-experiment-1-single-step-problem-performance admonition">
<p class="admonition-title"><em>Experiment 1 - Single-step problem performance</em></p>
<p>Similarly, as above but in this case, a single step 6-bit <a class="reference internal" href="../2_selected_topics/26_envs.html#section-topics-environments-rmpx"><span class="std std-ref">Real Multiplexer</span></a> environment is used, introducing much larger possible states space. Since calculating precise model knowledge is infeasible, the key performance indicators chosen are the average obtained reward and model size.</p>
</div>
<div class="admonition-experiment-2-multiple-step-problems-performance admonition">
<p class="admonition-title"><em>Experiment 2 - Multiple-step problems performance</em></p>
<p>Use two basic multistep environments (<a class="reference internal" href="../2_selected_topics/26_envs.html#section-topics-environments-corridor"><span class="std std-ref">Corridor</span></a> and <a class="reference internal" href="../2_selected_topics/26_envs.html#section-topics-environments-grid"><span class="std std-ref">Grid</span></a>) to determine the differences between the rate of gaining knowledge, the ability to build an internal pool of classifiers and operating in the environments.</p>
</div>
<div class="admonition-experiment-3-balacing-the-pole admonition">
<p class="admonition-title"><em>Experiment 3 - Balacing the pole</em></p>
<p>The methods will be evaluated on the <a class="reference internal" href="../2_selected_topics/26_envs.html#section-topics-environments-cartpole"><span class="std std-ref">Cart Pole</span></a> problem of balancing a pole on a cart. This is a novel problem for the LCS due to specific observation space (where two attributes span to infinity) and a specific reward scheme based on how long the pole is kept upright.</p>
</div>
</div>
<div class="section" id="experiments">
<h3>Experiments<a class="headerlink" href="#experiments" title="Permalink to this headline">¶</a></h3>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="41_experiment_1.html">Experiment 1 - Single-step problem performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="41_experiment_2.html">Experiment 2 - Multi-steps problems performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="41_experiment_3.html">Experiment 3 - Balancing the pole</a></li>
</ul>
</div>
</div>
<div class="section" id="answers-to-research-questions">
<h3>Answers to research questions<a class="headerlink" href="#answers-to-research-questions" title="Permalink to this headline">¶</a></h3>
<div class="section" id="q1-does-the-biased-exploration-methods-ad-ka-oiq-have-significantly-accelerate-the-agent-s-learning-speed">
<h4>Q1: Does the biased exploration methods (AD, KA, OIQ) have significantly accelerate the agent’s learning speed?<a class="headerlink" href="#q1-does-the-biased-exploration-methods-ad-ka-oiq-have-significantly-accelerate-the-agent-s-learning-speed" title="Permalink to this headline">¶</a></h4>
<p>Conducted research showed that biased exploration methods like AD and KA positively impact the knowledge evolution process. The OIQ performance was correlated with the basic EG method and did not yield any competitive performance.</p>
</div>
<div class="section" id="q2-can-the-oiq-method-improve-the-performance-in-terms-of-ingesting-knowledge-or-reducing-classifier-population-size">
<h4>Q2: Can the OIQ method improve the performance in terms of ingesting knowledge or reducing classifier population size?<a class="headerlink" href="#q2-can-the-oiq-method-improve-the-performance-in-terms-of-ingesting-knowledge-or-reducing-classifier-population-size" title="Permalink to this headline">¶</a></h4>
<p>The impact of initializing classifier quality with a higher (positive) value resulted in having a neglectable effect on all evaluated metrics. The OIQ, in theory, can perform better when forming a population of reliable classifiers, but for the investigated problems, the performance was highly correlated with a default EG method.</p>
</div>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./chapters/4_biased_exploration"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="41_introduction.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span class="section-number">4. </span>Optimizing formation of internal model</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="41_experiment_1.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Experiment 1 - Single-step problem performance</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Norbert Kozłowski<br/>
    
        &copy; Copyright 2022.<br/>
      <div class="extra_footer">
        <div>
  <p><a href="https://wit.pwr.edu.pl/en/">Faculty of Computer Science and Telecommunications</a> - <a href="https://dce.pwr.edu.pl/">Department of Computer Engineering</a></p>
  <p xmlns:cc="http://creativecommons.org/ns#" xmlns:dct="http://purl.org/dc/terms/"><a property="dct:title" rel="cc:attributionURL" href="https://khozzy.github.io/phd">Real-valued Anticipatory Classifier System</a> by <span property="cc:attributionName">Norbert Kozlowski</span> is licensed under <a href="http://creativecommons.org/licenses/by/4.0/?ref=chooser-v1" target="_blank" rel="license noopener noreferrer" style="display:inline-block;">CC BY 4.0<img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/cc.svg?ref=chooser-v1"><img style="height:22px!important;margin-left:3px;vertical-align:text-bottom;" src="https://mirrors.creativecommons.org/presskit/icons/by.svg?ref=chooser-v1"></a></p>
</div> 

      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>